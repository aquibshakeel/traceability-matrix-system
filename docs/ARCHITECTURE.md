# ğŸ— Architecture Guide

**Version:** 6.3.0  
**Last Updated:** December 20, 2025  
**Difficulty:** Intermediate  
**Prerequisites:** [Getting Started Guide](GETTING_STARTED.md)

---

## ğŸ“– Overview

This guide explains the system architecture of the AI-Driven Test Coverage System. You'll understand:
- High-level system design
- Component relationships
- Data flow and processing
- AI integration architecture
- Report generation pipeline
- Extension points

---

## ğŸ¯ System Overview

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER INPUT                           â”‚
â”‚  (config.json, baseline YAML, service code)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ORCHESTRATION LAYER                     â”‚
â”‚  - ServiceManager: Coordinates analysis                  â”‚
â”‚  - PathResolver: Resolves service/baseline paths         â”‚
â”‚  - EnvConfig: Environment configuration                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SCANNERS   â”‚  â”‚   AI PROVIDERS   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚
       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ANALYSIS LAYER                         â”‚
â”‚  - AITestCaseGenerator: Generates scenarios              â”‚
â”‚  - EnhancedCoverageAnalyzer: Matches tests to scenarios  â”‚
â”‚  - JourneyCoverageAnalyzer: E2E workflow analysis        â”‚
â”‚  - GitChangeDetector: Detects API changes                â”‚
â”‚  - HistoryManager: Tracks trends over time               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   REPORT LAYER                           â”‚
â”‚  - ReportGenerator: Creates HTML/JSON/CSV/MD reports     â”‚
â”‚  - Enhanced Template: Premium UI with visualizations     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OUTPUT                              â”‚
â”‚  (HTML reports, JSON data, historical snapshots)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Core Components

### 1. ServiceManager (`lib/core/ServiceManager.ts`)

**Purpose:** Central orchestrator for the entire analysis process.

**Responsibilities:**
- Load configuration from `.traceability/config.json`
- Iterate through enabled services
- Coordinate scanners and analyzers
- Trigger report generation

**Key Methods:**
```typescript
class ServiceManager {
  async analyzeAllServices(): Promise<void>
  async analyzeService(config: ServiceConfig): Promise<Report>
  private loadConfiguration(): Config
}
```

**Flow:**
```
1. Load config.json
2. For each enabled service:
   a. Scan APIs and tests
   b. Run AI analysis
   c. Generate reports
3. Save historical snapshots
```

---

### 2. PathResolver (`lib/utils/PathResolver.ts`)

**Purpose:** 4-tier fallback system for resolving file paths.

**Path Resolution Priority:**
```
1. Per-Service Environment Variables
   â†“ (if not found)
2. Shared Environment Variables
   â†“ (if not found)
3. Config File Paths
   â†“ (if not found)
4. Default Paths
```

**Key Methods:**
```typescript
class PathResolver {
  resolveServicePath(serviceName: string): string
  resolveBaselinePath(serviceName: string): string
  resolveJourneyPath(serviceName: string): string
}
```

**Example Resolution:**
```typescript
// Looking for customer-service path
1. Check: $CUSTOMER_SERVICE_PATH
2. Check: $SERVICE_PATH/customer-service
3. Check: config.services[].path
4. Default: ./services/customer-service
```

---

### 3. AI Provider Layer (`lib/ai/`)

**Purpose:** Multi-provider AI integration with abstraction layer.

**Architecture:**
```
AIProvider (interface)
    â”‚
    â”œâ”€â”€ AnthropicProvider (Claude)
    â””â”€â”€ OpenAIProvider (GPT)
```

**Key Components:**

**AIProvider Interface:**
```typescript
interface AIProvider {
  generateTestScenarios(apiSpec: string): Promise<Scenarios>
  matchTestToScenario(test: Test, scenarios: Scenario[]): Promise<Match>
  categorizeOrphanTest(test: Test): Promise<Category>
  suggestAdditionalScenarios(api: API): Promise<Scenarios>
}
```

**AIProviderFactory:**
```typescript
class AIProviderFactory {
  static create(config: AIConfig): AIProvider {
    switch(config.provider) {
      case 'anthropic': return new AnthropicProvider(config)
      case 'openai': return new OpenAIProvider(config)
    }
  }
}
```

**Provider Selection Flow:**
```
1. Check AI_PROVIDER env variable
2. Check config.ai.provider
3. Default to 'anthropic'
4. Create appropriate provider instance
5. Use throughout analysis
```

---

### 4. Scanner Layer

**APIScanner (`lib/core/APIScanner.ts`)**
- Scans service code for API endpoints
- Extracts HTTP methods, paths, parameters
- Parses Swagger/OpenAPI specs (if available)

**E2ETestScanner (`lib/core/E2ETestScanner.ts`)**
- Scans for end-to-end test files
- Identifies journey test methods
- Links E2E tests to business journeys

**TestParserFactory (`lib/core/TestParserFactory.ts`)**
- Creates language-specific test parsers
- Supported: JavaTestParser, TypeScriptTestParser, PythonTestParser, GoTestParser

**Language-Specific Parsers:**
```typescript
interface TestParser {
  parseTestFile(filePath: string): Test[]
  extractTestName(test: Test): string
  extractDisplayName(test: Test): string
}

// Implementations
- JavaTestParser (JUnit annotations)
- TypeScriptTestParser (Jest/describe blocks)
- PythonTestParser (pytest decorators)
- GoTestParser (Test functions)
```

---

### 5. Analysis Layer

**AITestCaseGenerator (`lib/core/AITestCaseGenerator.ts`)**

**Purpose:** Generate test scenarios from API specifications using AI.

**Process:**
```
1. Scan APIs from service
2. For each API endpoint:
   a. Build AI prompt with API details
   b. Request AI to generate scenarios
   c. Parse AI response into structured format
3. Save to ai_cases/{service}-ai.yml
```

**Prompt Structure:**
```
Analyze this API endpoint:
- Method: POST
- Path: /api/customers
- Parameters: {...}
- Expected responses: {...}

Generate comprehensive test scenarios covering:
- Happy cases
- Error cases
- Edge cases
- Security scenarios
```

---

**EnhancedCoverageAnalyzer (`lib/core/EnhancedCoverageAnalyzer.ts`)**

**Purpose:** Core coverage analysis with AI-powered matching.

**Responsibilities:**
- Load baseline scenarios
- Scan unit tests
- Match tests to scenarios using AI
- Detect coverage gaps
- Categorize orphan tests
- Calculate coverage metrics

**Matching Algorithm:**
```typescript
For each baseline scenario:
  1. Extract scenario description
  2. Send to AI with all unit tests
  3. AI returns:
     - Best matching test (if any)
     - Confidence level (HIGH/MEDIUM/LOW)
     - Coverage status (FULLY/PARTIALLY/NOT covered)
  4. Record match with file location and line number
```

**Coverage States:**
```
FULLY_COVERED:
  - Test exists
  - All aspects of scenario verified
  - Confidence: HIGH

PARTIALLY_COVERED:
  - Test exists
  - Some aspects missing
  - Confidence: MEDIUM

NOT_COVERED:
  - No matching test found
  - Gap identified
  - Priority assigned based on scenario category
```

---

**JourneyCoverageAnalyzer (`lib/core/JourneyCoverageAnalyzer.ts`)**

**Purpose:** Analyze end-to-end user workflow coverage.

**Process:**
```
1. Load journey definitions from journeys YAML
2. For each business journey:
   a. Get coverage for each step (API)
   b. Check for E2E test
   c. Calculate journey status:
      - FULLY_COVERED: All steps + E2E test
      - PARTIALLY_COVERED: Some steps, maybe E2E
      - AT_RISK: Missing pieces
      - NOT_COVERED: Nothing
   d. Identify weak points
3. Return journey analysis
```

**Journey Status Logic:**
```typescript
if (allStepsCovered && hasE2ETest) {
  status = 'FULLY_COVERED'
} else if (someStepsCovered || hasE2ETest) {
  status = 'PARTIALLY_COVERED'
} else if (hasE2ETest !== hasUnitTests) {
  status = 'AT_RISK'
} else {
  status = 'NOT_COVERED'
}
```

---

**GitChangeDetector (`lib/core/GitChangeDetector.ts`)**

**Purpose:** Detect API changes from Git history.

**Detection Process:**
```
1. Check if directory is git repo
2. Get recent commits (configurable range)
3. For each commit:
   a. Extract API-related changes
   b. Identify: Added, Modified, Removed APIs
   c. Determine impact on tests
4. Return change summary
```

**Change Categories:**
```
- ADDED: New API endpoints
- MODIFIED: Changed parameters/responses
- REMOVED: Deleted endpoints
```

---

**HistoryManager (`lib/core/HistoryManager.ts`)**

**Purpose:** Track coverage metrics over time.

**Storage:**
```
.traceability/history/
â”œâ”€â”€ {service}-{date}.json
â””â”€â”€ snapshots.json
```

**Snapshot Structure:**
```json
{
  "date": "2025-12-20",
  "coverage": 66.7,
  "totalScenarios": 30,
  "fullyCovered": 20,
  "gaps": {
    "p0": 2,
    "p1": 3,
    "p2": 5
  }
}
```

**Trend Calculation:**
```
1. Load all historical snapshots
2. Sort by date
3. Calculate changes:
   - Coverage delta
   - Scenario additions
   - Gap reduction
4. Generate trend data for charts
```

---

### 6. Report Layer

**ReportGenerator (`lib/core/ReportGenerator.ts`)**

**Purpose:** Generate multi-format reports from analysis data.

**Supported Formats:**
```
1. HTML - Premium interactive dashboard
2. JSON - CI/CD integration
3. CSV - Spreadsheet analysis
4. Markdown - Documentation
```

**Generation Process:**
```typescript
class ReportGenerator {
  async generateHTML(data: AnalysisData): Promise<string>
  async generateJSON(data: AnalysisData): Promise<string>
  async generateCSV(data: AnalysisData): Promise<string>
  async generateMarkdown(data: AnalysisData): Promise<string>
}
```

**HTML Report Flow:**
```
1. Load template: lib/templates/enhanced-report-v2.html
2. Inject analysis data:
   - Summary metrics
   - API coverage details
   - Traceability matrix
   - Gaps and orphans
   - Historical trends
3. Add visualizations (Chart.js)
4. Save to .traceability/reports/
5. Auto-open in browser (if enabled)
```

---

## ğŸ“Š Data Flow

### Complete Analysis Flow

```
START: npm run continue
â”‚
â”œâ”€â”€ Load Configuration
â”‚   â”œâ”€â”€ Read .traceability/config.json
â”‚   â””â”€â”€ Resolve paths with PathResolver
â”‚
â”œâ”€â”€ For Each Service:
â”‚   â”‚
â”‚   â”œâ”€â”€ 1. SCAN Phase
â”‚   â”‚   â”œâ”€â”€ APIScanner â†’ Find APIs
â”‚   â”‚   â”œâ”€â”€ TestScanner â†’ Find unit tests
â”‚   â”‚   â””â”€â”€ E2ETestScanner â†’ Find E2E tests
â”‚   â”‚
â”‚   â”œâ”€â”€ 2. LOAD Phase
â”‚   â”‚   â”œâ”€â”€ Load baseline scenarios
â”‚   â”‚   â””â”€â”€ Load journey definitions
â”‚   â”‚
â”‚   â”œâ”€â”€ 3. ANALYSIS Phase
â”‚   â”‚   â”œâ”€â”€ AI Provider Factory â†’ Create provider
â”‚   â”‚   â”œâ”€â”€ EnhancedCoverageAnalyzer
â”‚   â”‚   â”‚   â”œâ”€â”€ Match tests to scenarios (AI)
â”‚   â”‚   â”‚   â”œâ”€â”€ Detect gaps
â”‚   â”‚   â”‚   â””â”€â”€ Categorize orphans (AI)
â”‚   â”‚   â”œâ”€â”€ JourneyCoverageAnalyzer
â”‚   â”‚   â”‚   â””â”€â”€ Analyze E2E workflows
â”‚   â”‚   â”œâ”€â”€ GitChangeDetector
â”‚   â”‚   â”‚   â””â”€â”€ Detect API changes
â”‚   â”‚   â””â”€â”€ AI Suggestions
â”‚   â”‚       â””â”€â”€ Generate additional scenarios
â”‚   â”‚
â”‚   â”œâ”€â”€ 4. REPORT Phase
â”‚   â”‚   â”œâ”€â”€ ReportGenerator
â”‚   â”‚   â”‚   â”œâ”€â”€ Generate HTML
â”‚   â”‚   â”‚   â”œâ”€â”€ Generate JSON
â”‚   â”‚   â”‚   â”œâ”€â”€ Generate CSV
â”‚   â”‚   â”‚   â””â”€â”€ Generate Markdown
â”‚   â”‚   â””â”€â”€ Auto-open HTML report
â”‚   â”‚
â”‚   â””â”€â”€ 5. HISTORY Phase
â”‚       â””â”€â”€ HistoryManager
â”‚           â””â”€â”€ Save snapshot for trends
â”‚
â””â”€â”€ END: Reports generated
```

---

## ğŸ”Œ Extension Points

### Adding a New AI Provider

**Step 1: Create Provider Class**
```typescript
// lib/ai/providers/NewProvider.ts
import { AIProvider } from '../AIProvider'

export class NewProvider implements AIProvider {
  async generateTestScenarios(apiSpec: string) {
    // Implementation
  }
  
  async matchTestToScenario(test: Test, scenarios: Scenario[]) {
    // Implementation
  }
  
  // ... other methods
}
```

**Step 2: Update Factory**
```typescript
// lib/ai/AIProviderFactory.ts
case 'new-provider':
  return new NewProvider(config)
```

**Step 3: Update Config Schema**
```typescript
// config.json
{
  "ai": {
    "provider": "new-provider"
  }
}
```

### Adding a New Language Parser

**Step 1: Create Parser**
```typescript
// lib/parsers/RustTestParser.ts
import { TestParser } from './TestParser'

export class RustTestParser implements TestParser {
  parseTestFile(filePath: string): Test[] {
    // Parse Rust test files
  }
  
  extractTestName(test: Test): string {
    // Extract test name from #[test] annotation
  }
}
```

**Step 2: Register in Factory**
```typescript
// lib/core/TestParserFactory.ts
case 'rust':
  return new RustTestParser()
```

### Adding a New Report Format

**Step 1: Implement Generator**
```typescript
// lib/core/ReportGenerator.ts
async generateXML(data: AnalysisData): Promise<string> {
  // Convert data to XML format
}
```

**Step 2: Update Report Pipeline**
```typescript
if (formats.includes('xml')) {
  await this.generateXML(data)
}
```

---

## ğŸ”„ Key Workflows

### Workflow 1: First-Time Setup

```
1. User runs: npm run generate
   â”‚
   â”œâ”€â”€ ServiceManager loads config
   â”œâ”€â”€ For each service:
   â”‚   â”œâ”€â”€ APIScanner finds endpoints
   â”‚   â”œâ”€â”€ AITestCaseGenerator creates scenarios
   â”‚   â””â”€â”€ Save to ai_cases/
   â”‚
   â””â”€â”€ QA reviews and creates baseline YAML
```

### Workflow 2: Coverage Analysis

```
1. User runs: npm run continue
   â”‚
   â”œâ”€â”€ ServiceManager loads config
   â”œâ”€â”€ For each service:
   â”‚   â”œâ”€â”€ Load baseline scenarios
   â”‚   â”œâ”€â”€ Scan unit tests
   â”‚   â”œâ”€â”€ AI matches tests to scenarios
   â”‚   â”œâ”€â”€ Detect gaps and orphans
   â”‚   â”œâ”€â”€ Generate reports
   â”‚   â””â”€â”€ Save historical snapshot
   â”‚
   â””â”€â”€ Auto-open HTML report
```

### Workflow 3: Pre-Commit Hook

```
1. Developer runs: git commit
   â”‚
   â”œâ”€â”€ Pre-commit hook triggers
   â”œâ”€â”€ Run npm run continue
   â”œâ”€â”€ Check P0 gaps
   â”‚
   â”œâ”€â”€ If P0 gaps exist:
   â”‚   â””â”€â”€ Block commit with error
   â”‚
   â””â”€â”€ If no P0 gaps:
       â””â”€â”€ Allow commit
```

---

## ğŸ’¾ Data Storage

### File Structure

```
.traceability/
â”œâ”€â”€ config.json                   # System configuration
â”‚
â”œâ”€â”€ test-cases/
â”‚   â”œâ”€â”€ baseline/                 # QA-managed scenarios
â”‚   â”‚   â””â”€â”€ {service}-baseline.yml
â”‚   â”œâ”€â”€ ai_cases/                 # AI-generated scenarios
â”‚   â”‚   â””â”€â”€ {service}-ai.yml
â”‚   â””â”€â”€ journeys/                 # E2E workflow definitions
â”‚       â””â”€â”€ {service}-journeys.yml
â”‚
â”œâ”€â”€ reports/                      # Generated reports
â”‚   â”œâ”€â”€ {service}-report.html
â”‚   â”œâ”€â”€ {service}-report.json
â”‚   â”œâ”€â”€ {service}-report.csv
â”‚   â””â”€â”€ {service}-report.md
â”‚
â””â”€â”€ history/                      # Historical snapshots
    â”œâ”€â”€ {service}-{date}.json
    â””â”€â”€ snapshots.json
```

### Data Persistence

**Configuration:**
- Stored in: `.traceability/config.json`
- Format: JSON
- Version controlled: Yes

**Baseline Scenarios:**
- Stored in: `.traceability/test-cases/baseline/`
- Format: YAML
- Version controlled: Yes
- Managed by: QA team

**AI-Generated Scenarios:**
- Stored in: `.traceability/test-cases/ai_cases/`
- Format: YAML
- Version controlled: No (regenerated each run)
- Managed by: System (AI)

**Reports:**
- Stored in: `.traceability/reports/`
- Format: HTML, JSON, CSV, Markdown
- Version controlled: Optional
- Managed by: System

**Historical Data:**
- Stored in: `.traceability/history/`
- Format: JSON
- Version controlled: Optional
- Managed by: System

---

## ğŸ§ª Testing Architecture

The system itself is designed with testability in mind:

### Unit Testing

```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ PathResolver.test.ts
â”‚   â”œâ”€â”€ EnvConfig.test.ts
â”‚   â””â”€â”€ TestParser.test.ts
```

### Integration Testing

```
tests/
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ ServiceManager.test.ts
â”‚   â”œâ”€â”€ CoverageAnalyzer.test.ts
â”‚   â””â”€â”€ ReportGenerator.test.ts
```

### End-to-End Testing

```
tests/
â”œâ”€â”€ e2e/
â”‚   â”œâ”€â”€ full-analysis.test.ts
â”‚   â””â”€â”€ multi-service.test.ts
```

---

## ğŸ” Security Considerations

### API Key Management

- API keys stored in environment variables
- Never committed to version control
- Validated before use
- Support for multiple key types

### Data Privacy

- No sensitive data sent to AI
- Only test descriptions and API specs
- Source code not included in prompts
- User controls all data

### External Dependencies

- Minimal external dependencies
- Only trusted packages (Anthropic SDK, OpenAI SDK)
- Regular security audits
- Dependency pinning

---

## ğŸ“ˆ Performance Optimizations

### Caching Strategy

```
1. Configuration caching
   - Config loaded once per run
   
2. AI response caching
   - Cache scenario generation
   - Cache matching results
   
3. File system caching
   - Cache parsed test files
   - Cache API scans
```

### Parallel Processing

```typescript
// Analyze multiple services in parallel
await Promise.all(
  services.map(service => 
    this.analyzeService(service)
  )
)
```

### Incremental Analysis

```
Only re-analyze:
- Changed APIs (via Git detection)
- New tests
- Modified scenarios
```

---

## ğŸ”® Future Architecture Plans

### Planned Enhancements

1. **Local AI Models**
   - Support for Ollama
   - Privacy-focused deployments
   - No internet required

2. **Plugin System**
   - Custom analyzers
   - Custom report formats
   - Custom AI providers

3. **Database Backend**
   - PostgreSQL support
   - Better historical tracking
   - Advanced querying

4. **Real-time Analysis**
   - Watch mode for development
   - Instant feedback
   - IDE integration

---

## ğŸ“š Related Documentation

- **ğŸ“– [Getting Started](GETTING_STARTED.md)** - First-time setup
- **âš™ï¸ [Configuration Guide](CONFIGURATION.md)** - Configuration options
- **ğŸ‘¨â€ğŸ’» [Developer Guide](DEV_GUIDE.md)** - Development details
- **ğŸ“Š [Reports Guide](REPORTS_GUIDE.md)** - Understanding reports

---

**Version:** 6.3.0 | **Status:** Production Ready âœ…
