# ğŸ¯ Partial Coverage Demo & Test Mapping Guide

**Purpose:** Demonstrate how partial coverage works, how test mapping expands, and best practices for understanding traceability.

---

## ğŸ“Š What is Partial Coverage?

**Partial Coverage** occurs when a baseline scenario is partially tested by unit tests - meaning the test exists but doesn't fully validate all aspects of the scenario.

### Coverage Levels:

| Status | Meaning | Example |
|--------|---------|---------|
| **FULLY_COVERED** | Unit test(s) completely validate the scenario | Scenario: "When customer ID exists, return 200 with customer data"<br>Test: Checks status=200 AND validates customer object |
| **PARTIALLY_COVERED** | Unit test(s) exist but validation incomplete | Scenario: "When customer ID exists, return 200 with customer data"<br>Test: Checks status=200 BUT doesn't validate customer object |
| **NOT_COVERED** | No unit tests found for this scenario | Scenario exists in baseline, but no matching test |

---

## ğŸ”— Test Mapping Expansion (Clickable Details)

The HTML report includes **expandable test mapping** that shows exactly which unit tests cover each scenario.

### Example from Report:

```html
<details style="margin-top: 8px;">
  <summary style="cursor: pointer; color: #667eea;">
    ğŸ“„ Show details
  </summary>
  <div style="margin-top: 10px; padding: 10px; background: #f8f9fa;">
    <div><strong>File:</strong> <code>CustomerControllerTest.java</code></div>
    <div><strong>Line:</strong> 45</div>
    <div><strong>Match Confidence:</strong> HIGH</div>
  </div>
</details>
```

### How It Works:

1. **Click** the "ğŸ“„ Show details" to expand
2. **View** exact file path, line number, and confidence level
3. **Navigate** to the test file to verify coverage
4. **Assess** if the test truly validates the scenario

---

## ğŸ’¡ Partial Coverage Example: Real-World Scenario

### Baseline Scenario:
```yaml
GET /v1/customers/{id}:
  happy_case:
    - "When customer ID exists, return 200 with complete customer object including name, email, age"
```

### Unit Test (Partial Coverage):
```java
@Test
public void getCustomerById_WithValidId_Returns200() {
    // Given
    String customerId = "123";
    
    // When
    ResponseEntity<?> response = controller.getCustomerById(customerId);
    
    // Then
    assertEquals(HttpStatus.OK, response.getStatusCode());  // âœ… Checks status
    // âŒ MISSING: Doesn't validate customer object content
}
```

### Why This is Partial Coverage:

| Scenario Requirement | Test Validation | Status |
|---------------------|----------------|---------|
| Return 200 status | âœ… Verified | Covered |
| Return customer object | âŒ Not checked | Missing |
| Validate name field | âŒ Not checked | Missing |
| Validate email field | âŒ Not checked | Missing |
| Validate age field | âŒ Not checked | Missing |

**Result:** PARTIALLY_COVERED (1/5 validations)

### How to Fix:

```java
@Test
public void getCustomerById_WithValidId_ReturnsCompleteCustomer() {
    // Given
    String customerId = "123";
    
    // When
    ResponseEntity<CustomerResponse> response = controller.getCustomerById(customerId);
    
    // Then
    assertEquals(HttpStatus.OK, response.getStatusCode());  // âœ…
    assertNotNull(response.getBody());                      // âœ…
    assertEquals("John Doe", response.getBody().getName()); // âœ…
    assertEquals("john@example.com", response.getBody().getEmail()); // âœ…
    assertEquals(30, response.getBody().getAge());          // âœ…
}
```

**Result:** FULLY_COVERED (5/5 validations)

---

## ğŸš€ Test Mapping Confidence Levels

The AI analyzer assigns confidence levels to test-scenario matches:

### HIGH Confidence (âœ…)
- Test name semantically matches scenario
- Test validates expected behavior
- Strong keyword overlap (4+ common words)
- **Action:** Trust this mapping

### MEDIUM Confidence (âš ï¸)
- Test name partially matches scenario
- Test validates some but not all aspects
- Moderate keyword overlap (2-3 common words)
- **Action:** Review test to ensure full coverage

### LOW Confidence (âŒ)
- Test name weakly matches scenario
- Unclear if test validates scenario
- Minimal keyword overlap (1-2 common words)
- **Action:** Verify if this is correct match, may need refactoring

---

## ğŸ“‹ Best Practices

### For QA Teams:

1. **Review Partial Coverage**
   - Click "Show details" to see which tests are linked
   - Navigate to test files and verify completeness
   - Update baseline if scenarios are too broad

2. **Prioritize Gaps**
   - Focus on P0 gaps first (critical scenarios)
   - Use AI suggestions for additional scenarios
   - Copy YAML format for quick baseline updates

3. **Validate Traceability**
   - Check "Traceability Matrix" section
   - Ensure HIGH confidence matches
   - Investigate MEDIUM/LOW confidence matches

### For Dev Teams:

1. **Write Complete Tests**
   - Validate ALL aspects of scenario
   - Don't just check status codes
   - Include assertions for data validation

2. **Use Descriptive Test Names**
   - Match baseline scenario wording
   - Use "When X, then Y" format
   - Helps AI matching accuracy

3. **Fix Partial Coverage**
   - Expand tests to cover all validations
   - Split complex scenarios if needed
   - Aim for FULLY_COVERED status

---

## ğŸ¨ Visual Guide: Report Sections

### 1. Coverage Gaps (Top Priority)
```
âš ï¸ Coverage Gaps (5)
â”œâ”€ P0: Critical scenarios without tests
â”œâ”€ P1: Important scenarios missing coverage
â””â”€ P2: Nice-to-have scenarios
```

### 2. API Coverage Analysis
```
ğŸ¯ API Coverage Analysis
â”œâ”€ Actual Coverage (Baseline vs Unit Tests)
â”‚  â”œâ”€ 7 Fully covered
â”‚  â”œâ”€ 2 Partially covered âš ï¸
â”‚  â””â”€ 1 Missing unit tests âŒ
â””â”€ AI-Powered Analysis (from API Spec)
   â””â”€ 10 additional scenarios suggested ğŸ¤–
```

### 3. Traceability Matrix (Expandable)
```
ğŸ”— Traceability Matrix
â””â”€ GET /v1/customers/{id}
   â”œâ”€ Scenario: "When customer exists..."
   â”‚  â””â”€ âœ… Matched Unit Tests (2)
   â”‚     â”œâ”€ getCustomerById_WithValidId [HIGH]
   â”‚     â”‚  â””â”€ ğŸ“„ Show details (clickable)
   â”‚     â””â”€ getCustomerById_ReturnsCustomer [MEDIUM]
   â””â”€ [Click to expand each test]
```

### 4. Orphan Tests (Priority Sorted)
```
ğŸ” Orphan Unit Tests (10)
â”œâ”€ ğŸ“‹ Copy-Ready YAML (for QA)
â””â”€ Sorted by Priority:
   â”œâ”€ P0: Critical tests (2) ğŸš¨
   â”œâ”€ P1: Important tests (3)
   â””â”€ P2: Normal tests (5)
```

---

## ğŸ” Interactive Features

### 1. Expandable Sections
- Click **â–¼** next to section headers to collapse/expand
- Useful for focusing on specific areas
- Saves scrolling in large reports

### 2. Clickable Test Details
- Click **"ğŸ“„ Show details"** to see:
  - Full file path
  - Line number
  - Match confidence
  - QA action (if needed)

### 3. Copy YAML Button
- One-click copy for orphan tests
- Pre-formatted for baseline YAML
- Grouped by API endpoint
- Categorized (happy_case, error_case, etc.)

---

## ğŸ“ˆ Metrics Tracking

### Coverage Percentage Calculation:
```
Coverage % = (Fully Covered / Total Scenarios) Ã— 100
```

**Note:** Partial coverage is NOT counted as covered.

### Example:
- Total Scenarios: 35
- Fully Covered: 17
- Partially Covered: 3
- Not Covered: 15

**Coverage: 48.6%** (17/35, partial not counted)

### Gap Priority Breakdown:
```
Total Gaps: 18
â”œâ”€ P0: 2 (Critical - blocks commit)
â”œâ”€ P1: 3 (Important - review required)
â””â”€ P2: 13 (Normal - nice to have)
```

---

## ğŸ¯ Success Criteria

### Excellent Coverage (>90%)
- âœ… All critical scenarios covered
- âœ… No P0 gaps
- âœ… Most scenarios FULLY_COVERED
- âœ… Few orphan tests

### Good Coverage (70-90%)
- âœ… Critical scenarios covered
- âš ï¸ Some P1/P2 gaps
- âš ï¸ Some PARTIALLY_COVERED
- âš ï¸ Some orphan tests

### Needs Improvement (<70%)
- âŒ Critical gaps exist
- âŒ Many NOT_COVERED
- âŒ Many PARTIALLY_COVERED
- âŒ Many orphan tests

---

## ğŸ’» CLI Quick Reference

### Run Full Analysis:
```bash
npm run analyze
```

### Generate AI Test Cases:
```bash
npm run generate
```

### Generate Reports Only:
```bash
npm run continue
```

### Open HTML Report:
```bash
open .traceability/reports/customer-service-report.html
```

---

## ğŸ“ Learning Resources

1. **AI-PRIORITY-LOGIC.md** - How AI prioritizes gaps
2. **TWO-PHASE-ANALYSIS-EXPLAINED.md** - System architecture
3. **SCENARIO-COMPLETENESS-DETECTION.md** - AI suggestions explained
4. **QA_GUIDE.md** - Full QA team guide
5. **DEV_GUIDE.md** - Full developer guide

---

## ğŸ“ Support

Need help? Check:
- ğŸ“– Documentation: `docs/` folder
- ğŸ› Report Issues: Use `/reportbug` in chat
- ğŸ’¡ Feature Requests: Create GitHub issue

---

**Last Updated:** December 11, 2025
**Version:** 1.0.0
