# AI-Driven Traceability System - Complete Testing Guide

## üìã Table of Contents

1. [System Capabilities](#system-capabilities)
2. [Pre-requisites](#pre-requisites)
3. [Test Case 1: Fresh Start - No Tests](#test-case-1-fresh-start---no-tests)
4. [Test Case 2: Partial Coverage](#test-case-2-partial-coverage)
5. [Test Case 3: Orphan Tests Detection](#test-case-3-orphan-tests-detection)
6. [Test Case 4: Orphan Unit Tests - NEW](#test-case-4-orphan-unit-tests---new)
7. [Test Case 5: Orphan APIs - NEW](#test-case-5-orphan-apis---new)
8. [Test Case 6: Scenario Completeness Check](#test-case-6-scenario-completeness-check)
9. [Test Case 7: Code Change Impact](#test-case-7-code-change-impact)
10. [Test Case 8: New API Added](#test-case-8-new-api-added)
11. [Test Case 9: API Removed](#test-case-9-api-removed)
12. [Test Case 10: Full Coverage Success](#test-case-10-full-coverage-success)
13. [Testing Checklist](#testing-checklist)
14. [Common Issues & Solutions](#common-issues--solutions)

---

## System Capabilities

### What This AI System Can Do

#### 1. **AI Test Scenario Generation**
- ‚úÖ Automatically generates test scenarios from API specifications
- ‚úÖ Analyzes Swagger/OpenAPI documentation
- ‚úÖ Scans code for API endpoints
- ‚úÖ Suggests comprehensive test coverage
- ‚úÖ **NEW**: Provides AI-suggested scenarios for orphan unit tests

**Scenario Types Generated:**
- **Happy Case**: Valid inputs, successful responses (201, 200)
- **Edge Case**: Boundary conditions, special characters, null/empty values
- **Error Case**: Validation errors (400, 404, 409, 422, 500)
- **Security**: SQL injection, XSS, authentication bypass

#### 2. **Smart Coverage Analysis**
- ‚úÖ Compares actual unit tests vs baseline scenarios
- ‚úÖ Calculates coverage percentage
- ‚úÖ AI-powered semantic matching (not just string matching)
- ‚úÖ Identifies gaps (scenarios without tests)
- ‚úÖ Categorizes orphan tests (tests without scenarios)
- ‚úÖ **NEW**: Detects orphan unit tests (unit tests without baseline scenarios)
- ‚úÖ **NEW**: Detects orphan APIs (APIs with NO scenarios AND NO tests)

#### 3. **Scenario Completeness Detection**
- ‚úÖ Compares QA baseline vs AI suggestions
- ‚úÖ Detects missing scenarios based on API spec
- ‚úÖ Suggests additional test cases
- ‚úÖ Prevents incomplete test coverage
- ‚úÖ **NEW**: Detects when unit tests exist but scenarios are missing

#### 4. **Change Impact Analysis**
- ‚úÖ Detects code changes via Git
- ‚úÖ Identifies affected unit tests
- ‚úÖ Marks scenarios needing re-verification
- ‚úÖ Tracks lines changed with before/after diff

#### 5. **Intelligent Test Categorization**
- ‚úÖ **Technical Tests** (P3): Infrastructure tests (DTOs, Entities, Mappers)
- ‚úÖ **Business Tests** (P0-P2): Controller/Service tests requiring scenarios
- ‚úÖ Priority-based recommendations
- ‚úÖ **NEW**: AI-powered scenario suggestions for business tests

#### 6. **Visual Analytics - NEW**
- ‚úÖ **Coverage Distribution**: Progress bars for covered/partial/not covered
- ‚úÖ **Gap Priority Breakdown**: Visual P0/P1/P2/P3 metrics
- ‚úÖ **Orphan Test Priority**: Priority-based orphan test distribution
- ‚úÖ **Coverage Trends**: Historical tracking (extensible)

#### 7. **Multi-Format Reporting**
- ‚úÖ **HTML**: Visual, interactive dashboard with analytics
- ‚úÖ **JSON**: Machine-readable for CI/CD
- ‚úÖ **CSV**: Spreadsheet analysis
- ‚úÖ **Markdown**: Documentation

#### 8. **Pre-Commit Validation**
- ‚úÖ Blocks commits with P0/P1 gaps
- ‚úÖ Allows commits with only P2/P3 gaps
- ‚úÖ Provides actionable recommendations

---

## Pre-requisites

### Environment Setup

```bash
# 1. Navigate to project directory
cd /Users/aquibshakeel/Desktop/traceability-matrix-system

# 2. Install dependencies
npm install

# 3. Set Claude API Key
export CLAUDE_API_KEY="sk-ant-your-key-here"
# OR
export ANTHROPIC_API_KEY="sk-ant-your-key-here"

# 4. Verify configuration exists
cat .traceability/config.json

# 5. Ensure baseline exists
ls -la .traceability/test-cases/baseline/

# 6. Check services
ls -la services/
```

### Required Files

```
traceability-matrix-system/
‚îú‚îÄ‚îÄ .traceability/
‚îÇ   ‚îú‚îÄ‚îÄ config.json                    # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ test-cases/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ baseline/                  # QA-managed scenarios
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ customer-service.yml   # Baseline scenarios
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ai_cases/                  # AI-generated (auto-created)
‚îÇ   ‚îî‚îÄ‚îÄ reports/                       # Generated reports (auto-created)
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ customer-service/              # Java service
‚îÇ   ‚îî‚îÄ‚îÄ identity-service/              # Java service
‚îî‚îÄ‚îÄ package.json
```

---

## Test Case 1: Fresh Start - No Tests

### Objective
Test the system with baseline scenarios but NO unit tests to validate gap detection.

### Setup

```bash
# 1. Ensure baseline exists
cat .traceability/test-cases/baseline/customer-service-baseline.yml
# Should show scenarios

# 2. Verify NO unit tests exist
ls services/customer-service/src/test/
# Should be empty or not exist

# 3. Clean previous reports
rm -rf .traceability/reports/*
rm -rf .traceability/test-cases/ai_cases/*
```

### Execute

```bash
# Run analysis
node bin/ai-continue customer-service
```

### Expected Output

#### Console Output:
```
üìä Analyzing: customer-service
‚úì Baseline: 25 scenarios
‚úì Unit tests: 0 found

ü§ñ AI analyzing coverage...
üìà Coverage: 0.0%
‚úÖ Covered: 0/25
‚ö†Ô∏è  Gaps: P0=5, P1=8, P2=12
```

### Verification Checklist

- [ ] System detects 0 unit tests
- [ ] Coverage shows 0%
- [ ] All scenarios marked as gaps
- [ ] P0/P1 gaps present
- [ ] HTML report shows:
  - Coverage: 0%
  - Coverage Gaps section with all scenarios
  - Recommendations for each gap

---

## Test Case 2: Partial Coverage

### Objective
Test with some scenarios covered by tests, some not.

### Setup

```bash
# Create sample unit test file with 10 tests
mkdir -p services/customer-service/src/test/java/com/pulse/customerservice/controller
```

### Execute

```bash
node bin/ai-continue customer-service
```

### Expected Output

```
‚úì Baseline: 25 scenarios
‚úì Unit tests: 10 found
üìà Coverage: 40.0%
‚úÖ Covered: 10/25
‚ö†Ô∏è  Gaps: P0=3, P1=5, P2=7
```

### Verification Checklist

- [ ] System finds 10 unit tests
- [ ] Coverage: ~40% (10/25)
- [ ] 10 scenarios marked as FULLY_COVERED
- [ ] 15 scenarios marked as gaps
- [ ] Report shows which scenarios are covered vs not

---

## Test Case 3: Orphan Tests Detection

### Objective
Test with tests that don't have corresponding scenarios (traditional orphans).

### Setup

```bash
# Add orphan tests to the test file (tests without any matching scenario)
```

### Expected Output

```
‚úì Baseline: 25 scenarios
‚úì Unit tests: 15 found
üîç Categorizing orphan tests...
  Found 5 orphan tests, categorizing...
  ‚úÖ Technical: 3, Business: 2
```

### Verification Checklist

- [ ] System finds all 15 tests
- [ ] Identifies 5 orphan tests (tests without scenarios)
- [ ] **Categorizes orphans:**
  - [ ] Technical (P3): 3 tests ‚Üí No action needed
  - [ ] Business (P0-P2): 2 tests ‚Üí QA should add scenarios
- [ ] Report shows "Orphan Tests" section
- [ ] Recommendations for business orphans

#### Expected Report Section:

```
Orphan Tests (5):

Tests without corresponding business scenarios. 2 require QA action, 3 are infrastructure tests.

Technical Tests: 3 (no action needed)
Business Tests: 2 (need scenarios)

Categorization:
  - TECHNICAL - Entity Test: 1 test (P3)
  - TECHNICAL - DTO Test: 1 test (P3)
  - TECHNICAL - Mapper Test: 1 test (P3)
  - BUSINESS - Controller Test: 2 tests (P2) [Action Required]
```

---

## Test Case 4: Orphan Unit Tests - NEW ‚≠ê

### Objective
**NEW FEATURE**: Test detection of unit tests that exist but have NO corresponding baseline scenarios (reverse orphan detection).

### What This Detects
- Unit tests that developers wrote
- But QA hasn't added scenarios to baseline yet
- Different from traditional orphan tests (tests without ANY scenario)
- This finds tests that should have baseline scenarios but don't

### Setup

```bash
# 1. Create unit tests that match API patterns
cat > services/customer-service/src/test/java/com/pulse/customerservice/controller/NewFeatureTest.java << 'EOF'
package com.pulse.customerservice.controller;

import org.junit.jupiter.api.Test;

public class NewFeatureTest {
    
    @Test
    public void getCustomer_ByEmail_ShouldReturn200() {
        // This is a real API test but NO scenario exists in baseline
    }
    
    @Test
    public void getCustomer_ByPhone_ShouldReturn200() {
        // Another API test without baseline scenario
    }
}
EOF

# 2. Ensure these tests are NOT in baseline
grep "ByEmail" .traceability/test-cases/baseline/customer-service-baseline.yml
# Should return nothing
```

### Execute

```bash
node bin/ai-continue customer-service
```

### Expected Output

```
/api/customer/{id}:
  üîç Checking for unit tests without test cases...
  ‚ö†Ô∏è  Found 2 unit tests without baseline scenarios
     - No test case for: "getCustomer_ByEmail_ShouldReturn200"
       üí° AI Suggestion: "When user fetches customer by email with valid format, then return 200 with customer details"
     - No test case for: "getCustomer_ByPhone_ShouldReturn200"
       üí° AI Suggestion: "When user fetches customer by phone number, then return 200 with customer details"
```

### Verification Checklist

- [ ] System detects unit tests without baseline scenarios
- [ ] Shows console message: "üîç Checking for unit tests without test cases..."
- [ ] For each orphan unit test:
  - [ ] Shows test name
  - [ ] **Provides AI-suggested scenario** (üí° AI Suggestion)
  - [ ] Shows file location
- [ ] Creates P2 gaps for these tests
- [ ] Report shows in "Coverage Gaps" section with label "ORPHAN UNIT TEST"

#### Expected Report Gap Entry:

```
Coverage Gaps:
  
  P2 | /api/customer/{id} | Unit test: getCustomer_ByEmail_ShouldReturn200
  
  Reason: Unit test exists but NO corresponding test case in baseline
  
  Recommendations:
    ‚ö†Ô∏è ORPHAN UNIT TEST: Test exists without baseline scenario
    Test: getCustomer_ByEmail_ShouldReturn200
    File: NewFeatureTest.java
    üí° AI-Suggested Scenario: "When user fetches customer by email with valid format, then return 200 with customer details"
    Action: QA should add this AI-suggested scenario to baseline
    If not suitable, create custom scenario based on test intent
```

### Key Differences from Test Case 3

**Test Case 3 (Traditional Orphan Tests):**
- Tests that don't match ANY scenario at all
- Usually technical tests (Entity, DTO, Mapper)
- System categorizes them as Technical vs Business

**Test Case 4 (Orphan Unit Tests - NEW):**
- Tests that SHOULD have baseline scenarios but don't
- Detected per-API during coverage analysis
- **System provides AI-suggested scenarios**
- QA should add these scenarios to baseline

---

## Test Case 5: Orphan APIs - NEW ‚≠ê

### Objective
**NEW FEATURE**: Test detection of APIs that have NO scenarios AND NO tests (completely untracked).

### What This Detects
- APIs that exist in code
- But have NO baseline scenarios
- AND have NO unit tests
- These are "forgotten" or "undocumented" APIs

### Setup

```bash
# 1. Create baseline with empty scenario sections
cat > .traceability/test-cases/baseline/customer-service-baseline.yml << 'EOF'
service: customer-service

POST /api/customers:
  happy_case: []
  edge_case: []
  error_case: []
  security: []

GET /api/customers/{id}:
  happy_case: []
  error_case: []

DELETE /api/customers/{id}:
  happy_case: []
  error_case: []
EOF

# 2. Ensure NO unit tests exist
rm -rf services/customer-service/src/test/
```

### Execute

```bash
node bin/ai-continue customer-service
```

### Expected Output

```
‚úì Baseline: 0 scenarios
‚úì Unit tests: 0 found

‚ÑπÔ∏è  Baseline and unit tests are both empty - skipping coverage analysis

üìä API Coverage Summary:
   Found 3 API endpoint(s) without test cases or unit tests:
   - POST /api/customers (no baseline, no unit tests)
   - GET /api/customers/{id} (no baseline, no unit tests)
   - DELETE /api/customers/{id} (no baseline, no unit tests)

‚ö†Ô∏è  Orphan APIs: 3 APIs with no scenarios AND no tests

‚úÖ No blocking issues - proceed with development
```

### Verification Checklist

- [ ] System detects 0 baseline scenarios
- [ ] System detects 0 unit tests
- [ ] Shows message: "Baseline and unit tests are both empty"
- [ ] Lists all orphan APIs with "(no baseline, no unit tests)"
- [ ] Shows: "‚ö†Ô∏è Orphan APIs: X APIs with no scenarios AND no tests"
- [ ] Does NOT block development (allows to proceed)
- [ ] Report includes "Orphan APIs" section

#### Expected Report Section:

```
Orphan APIs (3)

‚ö†Ô∏è Critical: These APIs were discovered but have NO scenarios or tests. 
They are completely untracked and represent gaps in test coverage.

Method | Endpoint                  | Controller | Line | Scenario | Test
-------|---------------------------|------------|------|----------|-----
POST   | /api/customers           | Unknown    | N/A  | ‚ùå       | ‚ùå
GET    | /api/customers/{id}      | Unknown    | N/A  | ‚ùå       | ‚ùå
DELETE | /api/customers/{id}      | Unknown    | N/A  | ‚ùå       | ‚ùå

üìã Recommended Actions:
  ‚Ä¢ Create scenarios to document expected behavior for each API
  ‚Ä¢ Add unit tests to verify API functionality
  ‚Ä¢ If APIs are deprecated, remove them from code
  ‚Ä¢ Ensure all new APIs are created with tests
```

### When This is NOT an Error

This situation is acceptable during:
- **Initial development** when starting fresh
- **Proof of concept** phases
- **API scaffolding** before implementation

The system allows development to proceed but provides visibility.

---

## Test Case 6: Scenario Completeness Check

### Objective
Test detection of missing scenarios when baseline is incomplete compared to AI suggestions.

### Execute

```bash
node bin/ai-generate-api customer-service
node bin/ai-continue customer-service
```

### Expected Output

```
Phase 1: AI Generation
‚úì AI generating scenarios from API spec

Phase 2: Coverage Analysis
‚ö†Ô∏è  API Completeness: 12 additional scenarios suggested by API spec
```

### Verification Checklist

- [ ] AI generates comprehensive scenarios from API spec
- [ ] System compares baseline vs AI suggestions
- [ ] Detects missing scenarios
- [ ] Creates "Completeness Gaps" in report
- [ ] AI cases file shows üÜï for missing scenarios

---

## Test Case 7: Code Change Impact

### Objective
Test change detection when developer modifies code.

### Setup

```bash
# Modify the controller file
git add services/customer-service/src/main/java/com/pulse/customerservice/controller/CustomerController.java
```

### Execute

```bash
node bin/ai-generate-api customer-service
```

### Expected Output

```
üîç Detecting Git changes...
‚úì Detected 1 API changes
  - Modified: POST /api/customers (CustomerController.java)
```

### Verification Checklist

- [ ] Git change detected
- [ ] Modified API identified
- [ ] Change details captured
- [ ] ai_cases file shows change markers

---

## Test Case 8: New API Added

### Objective
Test detection when developer adds a new API endpoint.

### Expected Output

```
‚úì Detected 1 API changes
  - Added: PATCH /api/customers/{id}

‚ö†Ô∏è  Orphan APIs: 1
  - PATCH /api/customers/{id}
    Status: No scenarios, No tests
    Priority: Critical
```

### Verification Checklist

- [ ] New API detected
- [ ] Marked as "Orphan API"
- [ ] AI generates scenarios for new API
- [ ] Critical priority assigned

---

## Test Case 9: API Removed

### Objective
Test detection when developer removes an API endpoint.

### Expected Output

```
‚úì Detected 1 API changes
  - Removed: DELETE /api/customers/{id}

‚ö†Ô∏è  Stale scenarios detected
  - DELETE /api/customers/{id} (3 scenarios)
  - Recommendation: Remove from baseline
```

### Verification Checklist

- [ ] Removed API detected
- [ ] System identifies stale scenarios
- [ ] Recommendations to cleanup baseline

---

## Test Case 10: Full Coverage Success

### Objective
Test successful scenario with 100% coverage and no issues.

### Expected Output

```
‚úì Baseline: 25 scenarios
‚úì Unit tests: 25 found
üìà Coverage: 100%
‚úÖ Covered: 25/25
‚ö†Ô∏è  Gaps: 0
üîç Orphans: 0

‚úÖ VALIDATION SUCCESSFUL
```

### Verification Checklist

- [ ] Coverage: 100%
- [ ] All scenarios covered
- [ ] 0 gaps
- [ ] 0 orphan tests
- [ ] 0 orphan unit tests
- [ ] 0 orphan APIs
- [ ] Report shows success status

---

## Testing Checklist

### Pre-Test Verification
- [ ] Node.js and npm installed
- [ ] Claude API key configured
- [ ] Git repository initialized
- [ ] Config file present
- [ ] Baseline file exists

### Core Features Tests
- [ ] Discovers APIs from Swagger
- [ ] Discovers APIs from code scan
- [ ] Generates comprehensive scenarios
- [ ] Compares with baseline correctly
- [ ] Detects git changes
- [ ] Identifies affected tests

### NEW Features Tests ‚≠ê
- [ ] **Orphan Unit Test Detection**
  - [ ] Detects unit tests without baseline scenarios
  - [ ] Provides AI-suggested scenarios (üí°)
  - [ ] Shows in Coverage Gaps with "ORPHAN UNIT TEST" label
  - [ ] Recommendations include suggested scenario
- [ ] **Orphan API Detection**
  - [ ] Detects APIs with NO scenarios AND NO tests
  - [ ] Shows in console output
  - [ ] Creates "Orphan APIs" section in report
  - [ ] Allows development to proceed (non-blocking)
- [ ] **Visual Analytics**
  - [ ] Coverage Distribution with progress bars
  - [ ] Gap Priority Breakdown (P0/P1/P2/P3)
  - [ ] Orphan Test Priority Breakdown
  - [ ] Displays in HTML report

### Coverage Analysis Tests
- [ ] Loads baseline scenarios correctly
- [ ] Parses Java unit tests
- [ ] Matches tests to scenarios (semantic matching)
- [ ] Calculates coverage percentage
- [ ] Detects gaps (scenarios without tests)
- [ ] Categorizes orphan tests
  - [ ] Technical tests (P3)
  - [ ] Business tests (P0-P2)
- [ ] Checks scenario completeness

### Reporting Tests
- [ ] HTML report generated
- [ ] JSON report generated
- [ ] CSV report generated
- [ ] Markdown report generated
- [ ] Reports contain all sections:
  - [ ] Coverage overview
  - [ ] Coverage gaps
  - [ ] Orphan tests
  - [ ] **NEW**: Orphan unit tests (in gaps)
  - [ ] **NEW**: Orphan APIs
  - [ ] **NEW**: Visual Analytics
  - [ ] Change impact
  - [ ] Recommendations

---

## Common Issues & Solutions

### Issue 1: API Key Not Found

**Error:**
```
‚ùå ERROR: Claude API key not found!
```

**Solution:**
```bash
export CLAUDE_API_KEY="sk-ant-your-key-here"
```

### Issue 2: No AI Suggestions for Orphan Unit Tests

**Expected Behavior:**
When AI cases file doesn't exist or has no matching scenarios, system shows:
```
- No test case for: "testName" (no AI suggestion available)
```

**To Get AI Suggestions:**
```bash
# Generate AI cases first
node bin/ai-generate-api customer-service

# Then run coverage analysis
node bin/ai-continue customer-service
```

### Issue 3: Orphan APIs Always Showing

**Expected:** Orphan APIs appear when baseline has empty scenario sections AND no unit tests.

**Solution:**
This is informational, not an error. Either:
1. Add scenarios to baseline
2. Create unit tests
3. Remove unused API endpoints from code

---

## Quick Reference

### Run Commands
```bash
# Generate AI scenarios
node bin/ai-generate-api <service-name>

# Analyze coverage
node bin/ai-continue <service-name>

# Full workflow
node bin/ai-generate-api customer-service
node bin/ai-continue customer-service
```

### File Locations
```
Baseline (QA-managed):
  .traceability/test-cases/baseline/<service>-baseline.yml

AI Cases (Auto-generated):
  .traceability/test-cases/ai_cases/<service>-ai.yml

Reports:
  .traceability/reports/<service>-report.html
  .traceability/reports/<service>-report.json
  .traceability/reports/<service>-report.csv
  .traceability/reports/<service>-report.md
```

### NEW Features Quick Ref ‚≠ê

**Orphan Unit Test Detection:**
- Checks: Unit tests exist but NO baseline scenario
- Output: "üîç Checking for unit tests without test cases..."
- AI Help: "üí° AI Suggestion: ..."
- Action: QA adds suggested scenario to baseline

**Orphan API Detection:**
- Checks: API has NO scenarios AND NO tests
- Output: "‚ö†Ô∏è Orphan APIs: X APIs..."
- Report: Dedicated "Orphan APIs" section
- Action: Add scenarios + tests, or remove API

**Visual Analytics:**
- Coverage Distribution (progress bars)
- Gap Priority Breakdown (P0/P1/P2/P3 grid)
- Orphan Test Priority Breakdown
- Located in: HTML report "Visual Analytics" section

---

## Success Criteria

‚úÖ **System is working correctly if:**
1. All 10 test cases pass (including new Test Cases 4 & 5)
2. Reports generated in all formats
3. Correct blocking/allowing behavior
4. Change detection works
5. Orphan categorization accurate
6. **NEW**: Orphan unit test detection works with AI suggestions
7. **NEW**: Orphan API detection works
8. **NEW**: Visual analytics display in HTML report
9. Scenario completeness detection works
10. Coverage calculations accurate

---

**Last Updated:** December 10, 2025  
**Version:** 2.0 (Added Orphan Unit Tests, Orphan APIs, Visual Analytics)  
**System:** AI-Driven Traceability Matrix
