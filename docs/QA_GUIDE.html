<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>QA Engineer Guide - AI-Driven Test Coverage System</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        :root {
            --primary-gradient: linear-gradient(135deg, #10b981 0%, #059669 100%);
            --success-color: #10b981;
            --warning-color: #f59e0b;
            --danger-color: #ef4444;
            --info-color: #3b82f6;
            --sidebar-width: 280px;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            color: #1e293b;
            background: #f8fafc;
        }
        .header {
            background: var(--primary-gradient);
            color: white;
            padding: 2rem;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            position: sticky;
            top: 0;
            z-index: 100;
        }
        .header h1 { font-size: 2rem; margin-bottom: 0.5rem; font-weight: 700; }
        .header-meta { display: flex; gap: 2rem; font-size: 0.9rem; opacity: 0.95; flex-wrap: wrap; }
        .container { display: flex; max-width: 1600px; margin: 0 auto; }
        .sidebar {
            width: var(--sidebar-width);
            background: white;
            padding: 2rem 1rem;
            position: sticky;
            top: 140px;
            height: calc(100vh - 140px);
            overflow-y: auto;
            border-right: 1px solid #e2e8f0;
        }
        .sidebar h3 {
            font-size: 0.875rem;
            text-transform: uppercase;
            color: #64748b;
            margin-bottom: 1rem;
            font-weight: 600;
        }
        .sidebar nav ul { list-style: none; }
        .sidebar nav li { margin-bottom: 0.5rem; }
        .sidebar nav a {
            color: #1e293b;
            text-decoration: none;
            display: block;
            padding: 0.5rem 1rem;
            border-radius: 0.375rem;
            transition: all 0.2s;
            font-size: 0.9rem;
        }
        .sidebar nav a:hover { background: var(--primary-gradient); color: white; transform: translateX(4px); }
        .main-content { flex: 1; padding: 2rem; max-width: calc(100% - var(--sidebar-width)); }
        .content-wrapper {
            background: white;
            padding: 3rem;
            border-radius: 0.5rem;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        h2 {
            font-size: 2rem;
            margin: 2rem 0 1rem;
            color: #1e293b;
            border-bottom: 3px solid transparent;
            border-image: var(--primary-gradient);
            border-image-slice: 1;
            padding-bottom: 0.5rem;
        }
        h3 { font-size: 1.5rem; margin: 1.5rem 0 1rem; color: #1e293b; }
        h4 { font-size: 1.25rem; margin: 1.25rem 0 0.75rem; color: #1e293b; }
        p { margin-bottom: 1rem; color: #1e293b; }
        .alert {
            padding: 1.25rem;
            border-radius: 0.5rem;
            margin: 1.5rem 0;
            border-left: 4px solid;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }
        .alert-info { background: #dbeafe; border-color: var(--info-color); color: #1e40af; }
        .alert-success { background: #d1fae5; border-color: var(--success-color); color: #065f46; }
        .alert-warning { background: #fef3c7; border-color: var(--warning-color); color: #92400e; }
        .alert-danger { background: #fee2e2; border-color: var(--danger-color); color: #991b1b; }
        .alert h4 { margin: 0 0 0.5rem; font-size: 1rem; }
        ul, ol { margin: 1rem 0 1rem 2rem; }
        li { margin-bottom: 0.5rem; }
        code {
            background: #f1f5f9;
            padding: 0.25rem 0.5rem;
            border-radius: 0.25rem;
            font-family: 'Monaco', 'Courier New', monospace;
            font-size: 0.875rem;
            color: #dc2626;
        }
        pre {
            background: #1e293b;
            color: #e2e8f0;
            padding: 1.5rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            margin: 1.5rem 0;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        pre code { background: none; padding: 0; color: inherit; }
        table { width: 100%; border-collapse: collapse; margin: 1.5rem 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        thead { background: var(--primary-gradient); color: white; }
        th, td { padding: 1rem; text-align: left; border: 1px solid #e2e8f0; }
        tbody tr:nth-child(even) { background: #f8fafc; }
        tbody tr:hover { background: #f1f5f9; }
        .scroll-top {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 3rem;
            height: 3rem;
            background: var(--primary-gradient);
            color: white;
            border: none;
            border-radius: 50%;
            cursor: pointer;
            display: none;
            align-items: center;
            justify-content: center;
            font-size: 1.5rem;
            box-shadow: 0 4px 6px rgba(0,0,0,0.2);
            transition: all 0.3s;
        }
        .scroll-top:hover { transform: translateY(-4px); }
        .scroll-top.visible { display: flex; }
        @media (max-width: 768px) {
            .sidebar { display: none; }
            .main-content { max-width: 100%; }
            .content-wrapper { padding: 1.5rem; }
            .header h1 { font-size: 1.5rem; }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üß™ QA Engineer Guide</h1>
        <div class="header-meta">
            <span><strong>Version:</strong> 6.3.0</span>
            <span><strong>Last Updated:</strong> December 20, 2025</span>
            <span><strong>Difficulty:</strong> Intermediate</span>
        </div>
    </div>

    <div class="container">
        <aside class="sidebar">
            <h3>üìã Contents</h3>
            <nav>
                <ul>
                    <li><a href="#overview">Overview</a></li>
                    <li><a href="#role">QA Role in System</a></li>
                    <li><a href="#workflows">Daily QA Workflows</a></li>
                    <li><a href="#scenarios">Writing Baseline Scenarios</a></li>
                    <li><a href="#journeys">Managing Business Journeys</a></li>
                    <li><a href="#reports">Working with Reports</a></li>
                    <li><a href="#orphans">Reviewing Orphan Tests</a></li>
                    <li><a href="#gaps">Gap Management</a></li>
                    <li><a href="#collaboration">Collaborating with Developers</a></li>
                    <li><a href="#metrics">Metrics and Reporting</a></li>
                </ul>
            </nav>
        </aside>

        <main class="main-content">
            <div class="content-wrapper">
                <section id="overview">
                    <h2>üìñ Overview</h2>
                    
                    <p>This guide is for QA engineers who:</p>
                    <ul>
                        <li>Write and maintain baseline test scenarios</li>
                        <li>Review AI-generated scenario suggestions</li>
                        <li>Monitor test coverage metrics</li>
                        <li>Define business journeys (E2E workflows)</li>
                        <li>Work with developers on gap resolution</li>
                    </ul>

                    <div class="alert alert-info">
                        <h4>üìö Prerequisites</h4>
                        <p>This guide assumes you've read:</p>
                        <ul style="margin-bottom: 0;">
                            <li><strong>Getting Started</strong> - Basic setup and usage</li>
                            <li><strong>Reports Guide</strong> - Understanding reports</li>
                        </ul>
                    </div>
                </section>

                <section id="role">
                    <h2>üéØ QA Role in the System</h2>

                    <h3>What QA Manages</h3>
                    <ol>
                        <li><strong>Baseline Scenarios</strong> (<code>.traceability/test-cases/baseline/</code>)
                            <ul>
                                <li>Authoritative test requirements</li>
                                <li>Version-controlled YAML files</li>
                                <li>One file per service</li>
                            </ul>
                        </li>
                        <li><strong>Business Journeys</strong> (<code>.traceability/test-cases/journeys/</code>)
                            <ul>
                                <li>End-to-end user workflows</li>
                                <li>Multi-step API sequences</li>
                                <li>E2E test verification</li>
                            </ul>
                        </li>
                        <li><strong>Coverage Quality</strong>
                            <ul>
                                <li>Review AI suggestions</li>
                                <li>Validate traceability</li>
                                <li>Prioritize gaps</li>
                                <li>Track metrics</li>
                            </ul>
                        </li>
                    </ol>

                    <h3>What System Provides</h3>
                    <ol>
                        <li><strong>AI-Generated Suggestions</strong> - Auto-generated from API specs</li>
                        <li><strong>Coverage Reports</strong> - HTML dashboards, gap analysis, orphan detection</li>
                        <li><strong>Automated Validation</strong> - Pre-commit hooks, CI/CD integration</li>
                    </ol>
                </section>

                <section id="workflows">
                    <h2>üîÑ Daily QA Workflows</h2>

                    <h3>Workflow 1: Morning Coverage Check</h3>
                    <pre><code># 1. Run analysis
npm run continue

# 2. Open report
open .traceability/reports/customer-service-report.html

# 3. Review:
# - Coverage percentage (target: >80%)
# - P0 gaps (should be 0)
# - New orphan tests
# - Historical trend</code></pre>

                    <h3>Workflow 2: Reviewing AI Suggestions</h3>
                    <pre><code># 1. Generate fresh AI scenarios
npm run generate

# 2. Review AI suggestions
cat .traceability/test-cases/ai_cases/customer-service-ai.yml

# 3. Compare with baseline
diff .traceability/test-cases/baseline/customer-service-baseline.yml \
     .traceability/test-cases/ai_cases/customer-service-ai.yml

# 4. Add valuable suggestions to baseline
# Edit: .traceability/test-cases/baseline/customer-service-baseline.yml

# 5. Re-analyze
npm run continue</code></pre>

                    <h3>Workflow 3: Adding New Service Scenarios</h3>
                    <pre><code># 1. Create baseline file
touch .traceability/test-cases/baseline/new-service-baseline.yml

# 2. Write initial scenarios
cat > .traceability/test-cases/baseline/new-service-baseline.yml << 'EOF'
service: new-service

POST /api/resource:
  happy_case:
    - When resource created with valid data, return 201
  error_case:
    - When resource created with missing field, return 400
EOF

# 3. Analyze
npm run continue

# 4. Review coverage
open .traceability/reports/new-service-report.html</code></pre>

                    <h3>Workflow 4: Sprint Planning</h3>
                    <pre><code># 1. Generate coverage report
npm run continue

# 2. Export to CSV
# Open: .traceability/reports/customer-service-report.csv

# 3. Filter by priority
# In Excel: Filter "Priority" column for P0, P1

# 4. Add to sprint backlog
# Create tickets for gaps

# 5. Track progress
# Re-run npm run continue daily</code></pre>
                </section>

                <section id="scenarios">
                    <h2>‚úçÔ∏è Writing Baseline Scenarios</h2>

                    <h3>Scenario Format</h3>
                    <p><strong>Template:</strong> <code>When [condition], [expected result]</code></p>

                    <h4>Good Examples</h4>
                    <pre><code>service: customer-service

POST /api/customers:
  happy_case:
    - When customer created with valid data, return 201 with customer ID
    - When customer created with all optional fields, save complete profile
  
  error_case:
    - When customer created with missing email, return 400 with validation error
    - When customer created with invalid email format, return 400
    - When customer created with duplicate email, return 409
  
  edge_case:
    - When customer name is at maximum length (255 chars), accept successfully
    - When customer age is 0, accept as valid
  
  security:
    - When customer created without authentication token, return 401
    - When customer name contains SQL injection attempt, sanitize and return 400</code></pre>

                    <h3>Scenario Categories</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>Category</th>
                                <th>Purpose</th>
                                <th>Priority</th>
                                <th>Examples</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>happy_case</td>
                                <td>Normal success flows</td>
                                <td>P3</td>
                                <td>Valid data returns 201</td>
                            </tr>
                            <tr>
                                <td>error_case</td>
                                <td>Expected failures</td>
                                <td>P1-P2</td>
                                <td>Missing fields return 400</td>
                            </tr>
                            <tr>
                                <td>edge_case</td>
                                <td>Boundary conditions</td>
                                <td>P2</td>
                                <td>Max length, zero values</td>
                            </tr>
                            <tr>
                                <td>security</td>
                                <td>Auth, injection, XSS</td>
                                <td>P0</td>
                                <td>No auth returns 401</td>
                            </tr>
                        </tbody>
                    </table>

                    <div class="alert alert-success">
                        <h4>‚úÖ Do:</h4>
                        <pre><code># Specific and testable
- When customer created with email "test@example.com", return 201

# Includes expected status code
- When login fails with wrong password, return 401

# Clear condition and result
- When OTP expired, return 401 with "OTP expired" message</code></pre>
                    </div>

                    <div class="alert alert-danger">
                        <h4>‚ùå Don't:</h4>
                        <pre><code># Too vague
- When customer is created, it works

# Missing status code
- When login fails, show error

# Unclear condition
- When something goes wrong, handle it</code></pre>
                    </div>
                </section>

                <section id="journeys">
                    <h2>üöÄ Managing Business Journeys</h2>

                    <h3>What Are Business Journeys?</h3>
                    <p>End-to-end user workflows across multiple API endpoints.</p>

                    <div class="alert alert-info">
                        <h4>Example:</h4>
                        <pre><code>Registration Flow:
  Step 1: POST /identity/register (Create account)
  Step 2: POST /identity/verify-otp (Verify email)
  Step 3: GET /identity/profile (Get profile)
  
Result: User has verified, active account</code></pre>
                    </div>

                    <h3>Journey File Format</h3>
                    <p><strong>Create:</strong> <code>.traceability/test-cases/journeys/{service}-journeys.yml</code></p>

                    <pre><code>service: identity-service

business_journeys:
  - id: user-registration
    name: "Complete User Registration Flow"
    description: "User registers, verifies email, and accesses profile"
    priority: P0
    steps:
      - api: "POST /identity/register"
        description: "Create new user account"
        required: true
      - api: "POST /identity/verify-otp"  
        description: "Verify email with OTP"
        required: true
      - api: "GET /identity/profile"
        description: "Retrieve user profile"
        required: false
    e2e_tests:
      - file: "RegistrationFlowE2ETest.java"
        methods:
          - "testCompleteRegistrationFlow"
    tags: ["onboarding", "authentication"]</code></pre>

                    <h3>Journey Status Meanings</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>Status</th>
                                <th>Meaning</th>
                                <th>Action</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>FULLY_COVERED üü¢</strong></td>
                                <td>All steps have unit tests (>80%)<br>E2E test exists</td>
                                <td>No action needed</td>
                            </tr>
                            <tr>
                                <td><strong>PARTIALLY_COVERED üü°</strong></td>
                                <td>Some steps have unit tests<br>OR missing E2E test</td>
                                <td>Complete coverage</td>
                            </tr>
                            <tr>
                                <td><strong>AT_RISK üü†</strong></td>
                                <td>Has E2E but weak unit tests<br>OR has unit tests but no E2E</td>
                                <td>Add missing layer</td>
                            </tr>
                            <tr>
                                <td><strong>NOT_COVERED üî¥</strong></td>
                                <td>No unit tests<br>No E2E test</td>
                                <td>Immediate attention</td>
                            </tr>
                        </tbody>
                    </table>
                </section>

                <section id="reports">
                    <h2>üìä Working with Reports</h2>

                    <h3>Key Sections for QA</h3>
                    <ol>
                        <li><strong>Executive Summary</strong> - Quick health check</li>
                        <li><strong>Coverage Gaps</strong> - Prioritized missing tests</li>
                        <li><strong>Orphan Tests</strong> - Tests without scenarios</li>
                        <li><strong>Business Journeys</strong> - E2E workflow coverage</li>
                        <li><strong>AI Suggestions</strong> - Additional scenarios</li>
                    </ol>

                    <h3>Daily Report Review</h3>
                    <pre><code># Open latest report
open .traceability/reports/customer-service-report.html

# Check these metrics:
1. Coverage % - Target: >80%
2. P0 Gaps - Target: 0
3. P1 Gaps - Target: <5
4. Orphan Business Tests - Review for baseline addition
5. Journey Status - All should be Fully Covered or Partial

# Export for stakeholders
# CSV available at: .traceability/reports/customer-service-report.csv</code></pre>
                </section>

                <section id="orphans">
                    <h2>üîç Reviewing Orphan Tests</h2>

                    <h3>What Are Orphan Tests?</h3>
                    <p>Unit tests that exist in codebase but aren't linked to any baseline scenario.</p>

                    <h3>Two Categories</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>Category</th>
                                <th>Description</th>
                                <th>Action Required</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Business Orphans</strong></td>
                                <td>Controller tests, Service tests, API tests</td>
                                <td>‚úÖ Add baseline scenarios</td>
                            </tr>
                            <tr>
                                <td><strong>Technical Orphans</strong></td>
                                <td>Entity tests, DTO tests, Mapper tests</td>
                                <td>‚ùå No action needed</td>
                            </tr>
                        </tbody>
                    </table>

                    <h3>Workflow for Business Orphans</h3>
                    <pre><code># 1. Open report
open .traceability/reports/customer-service-report.html

# 2. Find "Orphan Tests" section

# 3. For each Business orphan:
#    a. Read test name/file
#    b. Check AI suggestion (if available)
#    c. Decide: Add to baseline or mark as technical

# 4. Add to baseline:
cat >> .traceability/test-cases/baseline/customer-service-baseline.yml << 'EOF'

POST /api/customers/bulk:
  happy_case:
    - When customers created in bulk with valid data, return 201
EOF

# 5. Re-analyze to verify
npm run continue</code></pre>

                    <div class="alert alert-warning">
                        <h4>Example Orphan Review</h4>
                        <p><strong>Report Shows:</strong></p>
                        <pre><code>üíº Business Orphan [P1]
Test: testBulkCreateCustomers
File: CustomerControllerTest.java:145
üí° AI Suggestion: "When customers created in bulk with valid data array, 
                    return 201 with list of customer IDs"

Action: Add scenario to baseline</code></pre>
                        <p><strong>QA Action:</strong></p>
                        <pre><code># Add to baseline/customer-service-baseline.yml

POST /api/customers/bulk:
  happy_case:
    - When customers created in bulk with valid data array, return 201 with list of customer IDs
  error_case:
    - When bulk create with invalid customer data, return 400 with error details</code></pre>
                    </div>
                </section>

                <section id="gaps">
                    <h2>üéØ Gap Management</h2>

                    <h3>Gap Priorities</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>Priority</th>
                                <th>Action</th>
                                <th>Timeframe</th>
                                <th>Owner</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>P0</strong></td>
                                <td>Block commit</td>
                                <td>Immediate</td>
                                <td>Dev + QA</td>
                            </tr>
                            <tr>
                                <td><strong>P1</strong></td>
                                <td>Current sprint</td>
                                <td>This week</td>
                                <td>Dev + QA</td>
                            </tr>
                            <tr>
                                <td><strong>P2</strong></td>
                                <td>Next sprint</td>
                                <td>1-2 weeks</td>
                                <td>Dev</td>
                            </tr>
                            <tr>
                                <td><strong>P3</strong></td>
                                <td>Backlog</td>
                                <td>Future</td>
                                <td>Dev</td>
                            </tr>
                        </tbody>
                    </table>

                    <h3>Creating Tickets from Gaps</h3>
                    <pre><code>Title: [P0 Gap] Add unit test for customer duplicate email validation

Description:
Coverage Gap: POST /api/customers
Scenario: When customer created with duplicate email, return 409
Priority: P0 (Blocks commit)
Status: NOT_COVERED

Acceptance Criteria:
- Unit test verifies duplicate email returns 409
- Error message includes "Email already exists"
- Test name matches scenario description

Test Location: CustomerControllerTest.java
Baseline Reference: customer-service-baseline.yml:15</code></pre>
                </section>

                <section id="collaboration">
                    <h2>ü§ù Collaborating with Developers</h2>

                    <h3>Communication Tips</h3>

                    <div class="alert alert-success">
                        <h4>‚úÖ Effective:</h4>
                        <pre><code>"I reviewed AI suggestions and marked 8 high-value ones 
for this sprint"

"We have 3 P0 gaps blocking deployment and 5 P1 gaps 
for this sprint"

"These 5 business orphans need scenarios. The other 10 
are technical tests (no action needed)"</code></pre>
                    </div>

                    <div class="alert alert-danger">
                        <h4>‚ùå Ineffective:</h4>
                        <pre><code>"The AI suggested 50 scenarios, add them all"

"You have 20 gaps"

"Fix these 15 orphan tests"</code></pre>
                    </div>

                    <h3>Weekly Sync Agenda</h3>
                    <pre><code>1. Coverage Metrics (5 min)
   - Current: X%
   - Target: Y%
   - Trend: Up/Down

2. P0/P1 Gaps (10 min)
   - How many?
   - Owners?
   - Blockers?

3. New Features (10 min)
   - APIs added this week
   - Baseline scenarios needed
   - Test coverage plan

4. Orphan Review (5 min)
   - New business orphans
   - Scenarios to add

5. Journey Health (5 min)
   - Journey status update
   - E2E test gaps

Total: 35 minutes</code></pre>
                </section>

                <section id="metrics">
                    <h2>üìà Metrics and Reporting</h2>

                    <h3>Key Metrics for QA</h3>

                    <h4>Coverage Metrics</h4>
                    <ul>
                        <li>Overall Coverage %</li>
                        <li>Coverage by Priority (P0/P1/P2/P3)</li>
                        <li>Coverage by API</li>
                        <li>Coverage Trend (30 days)</li>
                    </ul>

                    <h4>Gap Metrics</h4>
                    <ul>
                        <li>P0 Gaps (should be 0)</li>
                        <li>P1 Gaps (target: <5)</li>
                        <li>P2 Gaps (track)</li>
                        <li>P3 Gaps (backlog)</li>
                    </ul>

                    <h4>Quality Metrics</h4>
                    <ul>
                        <li>Orphan Business Tests (decreasing?)</li>
                        <li>Orphan APIs (should be 0)</li>
                        <li>Journey Coverage (target: 100% P0 journeys)</li>
                        <li>Partially Covered Scenarios (decreasing?)</li>
                    </ul>

                    <h3>Monthly Report for Stakeholders</h3>
                    <pre><code>Slide 1: Coverage Overview
  - Current: X%
  - Last Month: Y%
  - Trend: +Z%

Slide 2: Gap Analysis
  - P0: 0 (‚úÖ Good)
  - P1: 3 (‚ö†Ô∏è Tracking)
  - Action Items: ...

Slide 3: Journey Health
  - P0 Journeys: 5/5 covered (‚úÖ)
  - P1 Journeys: 8/10 covered (‚ö†Ô∏è)
  - E2E Tests: 12/15 exist

Slide 4: Quality Improvements
  - Orphan Tests: 20 ‚Üí 5 (üìâ Good)
  - API Coverage: 75% ‚Üí 85% (üìà Good)
  - New Features: 3 fully covered</code></pre>
                </section>

                <section>
                    <h2>üéØ QA Checklist</h2>

                    <h3>Daily</h3>
                    <ul>
                        <li>Run <code>npm run continue</code> to check coverage</li>
                        <li>Review P0 gaps (should be 0)</li>
                        <li>Check for new orphan business tests</li>
                        <li>Monitor coverage trend</li>
                    </ul>

                    <h3>Weekly</h3>
                    <ul>
                        <li>Review AI suggestions</li>
                        <li>Update baseline with valuable scenarios</li>
                        <li>Sync with dev team on gaps</li>
                        <li>Review journey coverage</li>
                        <li>Update sprint back
