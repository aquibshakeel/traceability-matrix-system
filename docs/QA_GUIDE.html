<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>QA Guide - AI Test Coverage Analyzer</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; line-height: 1.6; color: #1a202c; background: #f7fafc; }
        .header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 40px 20px; text-align: center; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
        .header h1 { font-size: 2.5em; margin-bottom: 10px; }
        .header p { font-size: 1.2em; opacity: 0.9; }
        .container { display: flex; max-width: 1400px; margin: 0 auto; background: white; }
        .sidebar { width: 280px; background: #2d3748; color: white; padding: 20px; position: sticky; top: 0; height: 100vh; overflow-y: auto; }
        .sidebar h3 { color: #fff; margin-bottom: 15px; font-size: 1.1em; border-bottom: 2px solid #667eea; padding-bottom: 10px; }
        .sidebar ul { list-style: none; }
        .sidebar li { margin: 8px 0; }
        .sidebar a { color: #cbd5e0; text-decoration: none; display: block; padding: 8px 12px; border-radius: 5px; transition: all 0.3s; }
        .sidebar a:hover { background: #4a5568; color: #fff; transform: translateX(5px); }
        .content { flex: 1; padding: 40px 60px; max-width: 900px; }
        .content h2 { color: #667eea; font-size: 2em; margin: 40px 0 20px 0; padding-bottom: 10px; border-bottom: 3px solid #667eea; }
        .content h3 { color: #764ba2; font-size: 1.5em; margin: 30px 0 15px 0; }
        .content h4 { color: #667eea; font-size: 1.2em; margin: 20px 0 10px 0; }
        .badge { display: inline-block; padding: 4px 12px; border-radius: 20px; font-size: 0.85em; font-weight: bold; margin: 5px 5px 5px 0; }
        .badge-ai { background: #667eea; color: white; }
        .badge-success { background: #10b981; color: white; }
        .badge-info { background: #3b82f6; color: white; }
        .badge-warning { background: #f59e0b; color: white; }
        .code-block { background: #1a202c; color: #e2e8f0; padding: 20px; border-radius: 8px; margin: 15px 0; overflow-x: auto; font-family: 'Courier New', monospace; font-size: 0.9em; }
        .info-box { background: #eff6ff; border-left: 4px solid #3b82f6; padding: 15px 20px; margin: 15px 0; border-radius: 5px; }
        .warning-box { background: #fef3c7; border-left: 4px solid #f59e0b; padding: 15px 20px; margin: 15px 0; border-radius: 5px; }
        .success-box { background: #d1fae5; border-left: 4px solid #10b981; padding: 15px 20px; margin: 15px 0; border-radius: 5px; }
        table { width: 100%; border-collapse: collapse; margin: 20px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        table th { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 12px; text-align: left; }
        table td { padding: 12px; border-bottom: 1px solid #e2e8f0; }
        table tr:hover { background: #f7fafc; }
        ul, ol { margin: 15px 0 15px 25px; }
        li { margin: 8px 0; }
        code { background: #edf2f7; padding: 2px 6px; border-radius: 3px; font-family: 'Courier New', monospace; font-size: 0.9em; color: #d63384; }
        @media print { .sidebar { display: none; } .content { max-width: 100%; padding: 20px; } }
        @media (max-width: 1024px) { .container { flex-direction: column; } .sidebar { width: 100%; height: auto; position: relative; } .content { padding: 20px; } }
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ“‹ QA Guide</h1>
        <p>AI Test Coverage Analyzer v5.0.0</p>
    </div>
    <div class="container">
        <nav class="sidebar">
            <h3>ğŸ“‘ Table of Contents</h3>
            <ul>
                <li><a href="#overview">1. System Overview</a></li>
                <li><a href="#workflow">2. QA Workflow</a></li>
                <li><a href="#baselines">3. Writing Baselines</a></li>
                <li><a href="#generation">4. AI Test Generation</a></li>
                <li><a href="#analysis">5. Coverage Analysis</a></li>
                <li><a href="#interpretation">6. Interpreting Results</a></li>
                <li><a href="#best-practices">7. Best Practices</a></li>
                <li><a href="#examples">8. Real Examples</a></li>
                <li><a href="#troubleshooting">9. Troubleshooting</a></li>
            </ul>
        </nav>
        <main class="content">
            <section id="overview">
                <h2>1. System Overview ğŸ¯</h2>
                <h3>What Is It?</h3>
                <p>The <strong>AI Test Coverage Analyzer</strong> is a QA tool that uses Claude AI to analyze test coverage by comparing your baseline test scenarios against actual unit tests in the codebase.</p>
                <div class="info-box">
                    <strong>ğŸ’¡ Purpose:</strong> Ensure comprehensive test coverage and identify gaps automatically using AI intelligence.
                </div>
                <h3>Key Benefits for QA</h3>
                <ul>
                    <li><strong>AI-Powered:</strong> Claude understands test intent, not just text matching</li>
                    <li><strong>Automated Discovery:</strong> Finds coverage gaps without manual review</li>
                    <li><strong>Simple Baselines:</strong> Easy-to-write YAML format for test scenarios</li>
                    <li><strong>Actionable Feedback:</strong> AI tells you exactly what's missing</li>
                    <li><strong>Test Generation:</strong> AI generates comprehensive test scenarios from Swagger</li>
                </ul>

                <h3>Two-Phase System</h3>
                
                <div class="info-box">
                    <strong>ğŸ¤” Why Two Phases?</strong><br>
                    Even though pre-commit runs both phases automatically, they are <strong>separated so QA can run Phase 1 independently!</strong>
                    <br><br>
                    <strong>Phase 1 is designed for QA to run separately</strong> - not just for pre-commit automation. This gives QA full control over baseline management.
                </div>
                
                <table>
                    <tr>
                        <th>Phase</th>
                        <th>Command</th>
                        <th>Purpose</th>
                        <th>When QA Uses It</th>
                    </tr>
                    <tr>
                        <td><span class="badge badge-ai">Phase&nbsp;1</span></td>
                        <td><code>npm run generate</code></td>
                        <td>Generate AI test scenarios from APIs</td>
                        <td><strong>QA runs this separately</strong> to get AI suggestions for baseline</td>
                    </tr>
                    <tr>
                        <td><span class="badge badge-success">Phase&nbsp;2</span></td>
                        <td><code>npm run continue</code></td>
                        <td>Analyze test coverage against baseline</td>
                        <td>After developers write tests</td>
                    </tr>
                </table>
                
                <h4>QA Workflow Benefits</h4>
                <ul>
                    <li><strong>âœ… QA Control:</strong> QA team decides which AI suggestions to add to baseline</li>
                    <li><strong>âœ… Baseline Management:</strong> Add, update, or remove scenarios independently</li>
                    <li><strong>âœ… Flexibility:</strong> Don't wait for pre-commit - generate scenarios anytime</li>
                    <li><strong>âœ… Planning:</strong> Use AI suggestions for test planning and sprint work</li>
                </ul>
                
                <div class="success-box">
                    <strong>Pre-Commit Integration:</strong> Pre-commit automatically runs both phases together, but QA can still run Phase 1 separately whenever needed. This separation gives QA full control over baseline management!
                </div>

                <h3>How to Use Phase 1 (QA Independent Generation)</h3>
                
                <h4>Running Phase 1 Separately</h4>
                <div class="code-block">
# Set Claude API key (one time setup)
export CLAUDE_API_KEY="sk-ant-your-key"

# Run Phase 1 - Generate AI test scenarios
npm run generate

# Output location
.traceability/test-cases/ai_cases/{service}-ai.yml
                </div>

                <h4>When QA Should Run Phase 1</h4>
                <table>
                    <tr>
                        <th>Situation</th>
                        <th>Action</th>
                        <th>Benefit</th>
                    </tr>
                    <tr>
                        <td>New APIs added</td>
                        <td>Run <code>npm run generate</code></td>
                        <td>Get AI suggestions for new endpoints</td>
                    </tr>
                    <tr>
                        <td>Swagger updated</td>
                        <td>Run <code>npm run generate</code></td>
                        <td>Refresh scenarios based on latest API specs</td>
                    </tr>
                    <tr>
                        <td>Sprint planning</td>
                        <td>Run <code>npm run generate</code></td>
                        <td>Use AI suggestions for test planning</td>
                    </tr>
                    <tr>
                        <td>Baseline refresh needed</td>
                        <td>Run <code>npm run generate</code></td>
                        <td>Get new scenario ideas from AI</td>
                    </tr>
                </table>

                <h4>Phase 1 QA Workflow</h4>
                <ol>
                    <li><strong>Run Generation:</strong> Execute <code>npm run generate</code></li>
                    <li><strong>Review AI Output:</strong> Check <code>.traceability/test-cases/ai_cases/</code></li>
                    <li><strong>Evaluate Scenarios:</strong> Decide which AI suggestions are valuable</li>
                    <li><strong>Update Baseline:</strong> Add/modify scenarios in <code>baseline/{service}.yml</code></li>
                    <li><strong>Commit Changes:</strong> Push updated baseline to git</li>
                </ol>

                <div class="info-box">
                    <strong>ğŸ’¡ Key Point:</strong> Phase 1 is <strong>QA-driven</strong>. You control what goes into the baseline. AI provides suggestions, but you make the final decisions based on your domain knowledge and testing strategy!
                </div>
            </section>

            <section id="workflow">
                <h2>2. QA Workflow ğŸ”„</h2>
                
                <h3>Step-by-Step Process</h3>
                <ol>
                    <li><strong>Generate Test Scenarios (Optional)</strong>
                        <ul>
                            <li>Run <code>npm run generate</code> to get AI suggestions from Swagger</li>
                            <li>Review AI-generated test cases in <code>.traceability/test-cases/ai_cases/</code></li>
                            <li>Use as inspiration for your baseline</li>
                        </ul>
                    </li>
                    <li><strong>Create/Update Baseline</strong>
                        <ul>
                            <li>Write baseline scenarios in <code>.traceability/test-cases/baseline/{service}-baseline.yml</code></li>
                            <li>Define happy_case, edge_case, error_case, security scenarios</li>
                            <li>Commit baseline to git (version control)</li>
                        </ul>
                    </li>
                    <li><strong>Run Coverage Analysis</strong>
                        <ul>
                            <li>Execute <code>npm run continue</code></li>
                            <li>AI analyzes which tests cover your scenarios</li>
                            <li>Review AI feedback in console output</li>
                        </ul>
                    </li>
                    <li><strong>Take Action on Gaps</strong>
                        <ul>
                            <li>Identify scenarios marked as NOT COVERED or PARTIAL</li>
                            <li>Create JIRA tickets for developers to add tests</li>
                            <li>Re-run analysis after tests are added</li>
                        </ul>
                    </li>
                    <li><strong>Iterate</strong>
                        <ul>
                            <li>Update baseline as APIs evolve</li>
                            <li>Run analysis regularly (sprint end, before release)</li>
                            <li>Track coverage trends over time</li>
                        </ul>
                    </li>
                </ol>

                <h3>Typical Sprint Workflow</h3>
                <div class="code-block">
Week 1: Sprint Planning
  - Run generate to discover new APIs
  - Create baseline for new features

Week 2-3: Development
  - Developers write unit tests
  - QA updates baseline as requirements clarify

Week 4: Sprint End
  - Run analysis to verify coverage
  - Create tickets for gaps
  - Report coverage metrics to team
                </div>
            </section>

            <section id="baselines">
                <h2>3. Writing Baselines ğŸ“</h2>
                
                <h3>Baseline Structure</h3>
                <p>Location: <code>.traceability/test-cases/baseline/{service-name}-baseline.yml</code></p>

                <div class="code-block">
service: service-name

{HTTP_METHOD} {API_PATH}:
  happy_case:
    - "Scenario description"
  edge_case:
    - "Scenario description"
  error_case:
    - "Scenario description"
  security:
    - "Scenario description"
                </div>

                <h3>Four Scenario Categories</h3>
                <table>
                    <tr>
                        <th>Category</th>
                        <th>What to Test</th>
                        <th>Examples</th>
                    </tr>
                    <tr>
                        <td><strong>happy_case</strong></td>
                        <td>Normal, successful flows</td>
                        <td>
                            - Valid input returns 200<br>
                            - Data is saved correctly<br>
                            - Response includes all fields
                        </td>
                    </tr>
                    <tr>
                        <td><strong>edge_case</strong></td>
                        <td>Boundary conditions, limits</td>
                        <td>
                            - Empty list returns 200<br>
                            - Maximum items per page<br>
                            - Minimum/maximum field values
                        </td>
                    </tr>
                    <tr>
                        <td><strong>error_case</strong></td>
                        <td>Error handling, validation</td>
                        <td>
                            - Missing field returns 400<br>
                            - Invalid format returns 400<br>
                            - Not found returns 404
                        </td>
                    </tr>
                    <tr>
                        <td><strong>security</strong></td>
                        <td>Auth, authorization, security</td>
                        <td>
                            - No token returns 401<br>
                            - Insufficient perms returns 403<br>
                            - SQL injection blocked
                        </td>
                    </tr>
                </table>

                <h3>Writing Good Scenarios</h3>
                <div class="success-box">
                    <strong>âœ… Good Scenario:</strong><br>
                    "Create customer with valid email and phone returns 201 with customer ID"
                    <ul style="margin-top: 10px;">
                        <li>âœ“ Specific action</li>
                        <li>âœ“ Clear input conditions</li>
                        <li>âœ“ Expected outcome</li>
                    </ul>
                </div>

                <div class="warning-box">
                    <strong>âŒ Bad Scenario:</strong><br>
                    "Test customer creation"
                    <ul style="margin-top: 10px;">
                        <li>âœ— Too vague</li>
                        <li>âœ— No input specified</li>
                        <li>âœ— No expected outcome</li>
                    </ul>
                </div>

                <h3>Complete Example</h3>
                <div class="code-block">
service: customer-service

POST /api/customers:
  happy_case:
    - "Create customer with valid data returns 201"
    - "Customer ID is generated and returned in response"
    - "Customer data is persisted to database"
  edge_case:
    - "Create customer with only required fields succeeds"
    - "Create customer with maximum name length succeeds"
  error_case:
    - "Create customer with missing email returns 400"
    - "Create customer with invalid email format returns 400"
    - "Create customer with duplicate email returns 409"
  security:
    - "Create customer without auth token returns 401"
    - "Create customer with invalid token returns 401"

GET /api/customers:
  happy_case:
    - "Get all customers returns 200 with array"
    - "Response includes customer IDs, names, emails"
  edge_case:
    - "Get customers with empty database returns empty array"
    - "Get customers with pagination returns correct page"
  error_case:
    - "Get customers with invalid page number returns 400"
  security:
    - "Get customers without auth returns 401"
                </div>
            </section>

            <section id="generation">
                <h2>4. AI Test Generation ğŸ¤–</h2>
                
                <h3>Purpose</h3>
                <p>Use AI to automatically generate comprehensive test scenarios from your Swagger/OpenAPI specifications.</p>

                <h3>Running Generation</h3>
                <div class="code-block">
# Set Claude API key
export CLAUDE_API_KEY="sk-ant-your-key"

# Generate test scenarios
npm run generate

# Output: .traceability/test-cases/ai_cases/{service}-ai.json
                </div>

                <h3>What Gets Generated</h3>
                <ul>
                    <li><strong>Happy Path Tests:</strong> Normal successful scenarios</li>
                    <li><strong>Edge Cases:</strong> Boundary conditions and limits</li>
                    <li><strong>Error Cases:</strong> Validation failures, error handling</li>
                    <li><strong>Security Tests:</strong> Authentication, authorization</li>
                </ul>

                <h3>Using Generated Scenarios</h3>
                <ol>
                    <li>Review AI-generated file: <code>.traceability/test-cases/ai_cases/{service}-ai.json</code></li>
                    <li>Identify good scenarios to add to your baseline</li>
                    <li>Copy relevant scenarios to <code>baseline/{service}-baseline.yml</code></li>
                    <li>Edit and refine as needed</li>
                    <li>Commit baseline to git</li>
                </ol>

                <div class="info-box">
                    <strong>ğŸ’¡ Pro Tip:</strong> AI-generated scenarios are suggestions. Always review and refine them based on your domain knowledge!
                </div>

                <h3>Example Generated Output</h3>
                <div class="code-block">
{
  "service": "customer-service",
  "endpoints": {
    "POST /api/customers": {
      "happy_case": [
        "Create customer with all valid fields returns 201",
        "Customer ID is generated and included in response",
        "Customer data is correctly saved to database"
      ],
      "edge_case": [
        "Create customer with only required fields succeeds",
        "Create customer with special characters in name",
        "Create customer with international phone format"
      ],
      "error_case": [
        "Missing required field 'email' returns 400",
        "Invalid email format returns 400 with error message",
        "Duplicate email returns 409 conflict"
      ],
      "security": [
        "No authentication token returns 401 unauthorized",
        "Expired token returns 401 with token expired message"
      ]
    }
  }
}
                </div>

                <h3><span class="badge badge-ai">NEW</span> Generate Test Cases for Single API</h3>
                <p>Quickly generate AI test scenarios for ONE specific API endpoint - perfect for when you don't want to regenerate all APIs!</p>

                <div class="success-box">
                    <strong>âœ¨ QA-Only Feature:</strong> This tool is designed specifically for QA to quickly get AI suggestions for individual endpoints without affecting the main generation flow.
                </div>

                <h4>Quick Usage</h4>
                <div class="code-block">
# Generate scenarios for a specific API endpoint
npm run generate:api -- --service customer-service --endpoint "POST /api/customers"

# With path parameters
npm run generate:api -- --service identity-service --endpoint "GET /api/users/{id}"

# Different HTTP methods
npm run generate:api -- --service customer-service --endpoint "GET /api/customers"
npm run generate:api -- --service customer-service --endpoint "PUT /api/customers/{id}"
npm run generate:api -- --service customer-service --endpoint "DELETE /api/customers/{id}"

# Custom output path (optional)
npm run generate:api -- --service customer-service --endpoint "POST /api/customers" --output my-scenarios.json
                </div>

                <h4>When to Use</h4>
                <table>
                    <tr>
                        <th>Scenario</th>
                        <th>Use This Tool</th>
                    </tr>
                    <tr>
                        <td>New API endpoint added</td>
                        <td>âœ… Generate scenarios just for that endpoint</td>
                    </tr>
                    <tr>
                        <td>Need to refresh one API's scenarios</td>
                        <td>âœ… Quick regeneration for single endpoint</td>
                    </tr>
                    <tr>
                        <td>Want inspiration for test cases</td>
                        <td>âœ… Get AI suggestions for planning</td>
                    </tr>
                    <tr>
                        <td>Don't want full regeneration</td>
                        <td>âœ… Fast, focused, independent</td>
                    </tr>
                </table>

                <h4>Example Output</h4>
                <div class="code-block">
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ¤– AI Test Case Generator - Single API                   â•‘
â•‘  QA Tool for Generating Scenarios for One Endpoint        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ Service: customer-service
ğŸ”— Endpoint: POST /api/customers

âœ“ Service configuration loaded
ğŸ” Analyzing endpoint: POST /api/customers
âœ“ Found Swagger specification
âœ“ Endpoint found in Swagger

ğŸ¤– Generating test scenarios with AI...
âœ“ Scenarios generated successfully

âœ… Success! Test scenarios generated
ğŸ“„ Output file: .traceability/test-cases/ai_cases/customer-service-POST__api_customers-ai.json

ğŸ“Š Summary:
   Categories: 4
   Total Scenarios: 15

ğŸ“ Generated Scenarios:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  HAPPY CASE (4):
    1. When customer created with valid data, return 201
    2. When customer ID is generated and returned
    3. When customer data is persisted to database
    4. When response includes all required fields

  EDGE CASE (3):
    1. When created with only required fields
    2. When name contains special characters
    3. When email has international format

  ERROR CASE (5):
    1. When created with missing email, return 400
    2. When created with invalid email format, return 400
    3. When created with duplicate email, return 409
    4. When created without required fields, return 422
    5. When server error occurs, return 500

  SECURITY (3):
    1. When created without auth token, return 401
    2. When created with invalid token, return 401
    3. When SQL injection attempted, reject with 400

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ’¡ Next Steps:
   1. Review the generated scenarios
   2. Add relevant scenarios to your baseline file
   3. Baseline location: .traceability/test-cases/baseline/customer-service.yml
                </div>

                <h4>Key Benefits</h4>
                <ul>
                    <li><strong>âš¡ Fast:</strong> Only generates for one API (seconds vs minutes)</li>
                    <li><strong>ğŸ¯ Focused:</strong> Get scenarios for exactly what you need</li>
                    <li><strong>ğŸ”„ Flexible:</strong> Run anytime without affecting other APIs</li>
                    <li><strong>ğŸ”§ Independent:</strong> Doesn't trigger full generation flow</li>
                    <li><strong>ğŸ¤– AI-Powered:</strong> Same intelligent scenario generation</li>
                </ul>

                <h4>Comparison: Full vs Single API Generation</h4>
                <table>
                    <tr>
                        <th>Feature</th>
                        <th><code>npm run generate</code></th>
                        <th><code>npm run generate:api</code> <span class="badge badge-ai">NEW</span></th>
                    </tr>
                    <tr>
                        <td><strong>Scope</strong></td>
                        <td>All APIs in service</td>
                        <td>One specific endpoint</td>
                    </tr>
                    <tr>
                        <td><strong>Speed</strong></td>
                        <td>Minutes (many APIs)</td>
                        <td>Seconds (one API)</td>
                    </tr>
                    <tr>
                        <td><strong>When</strong></td>
                        <td>Pre-commit, scheduled</td>
                        <td>Anytime, on-demand</td>
                    </tr>
                    <tr>
                        <td><strong>Purpose</strong></td>
                        <td>Complete refresh</td>
                        <td>Quick scenarios</td>
                    </tr>
                    <tr>
                        <td><strong>QA Control</strong></td>
                        <td>Review all suggestions</td>
                        <td>Review one endpoint</td>
                    </tr>
                    <tr>
                        <td><strong>Use Case</strong></td>
                        <td>Full regeneration</td>
                        <td>New API, quick ideas</td>
                    </tr>
                </table>

                <div class="info-box">
                    <strong>ğŸ’¡ Pro Tip:</strong> Use <code>generate:api</code> when you want quick AI suggestions for a new endpoint without waiting for full generation. Perfect for sprint planning and rapid iteration!
                </div>
            </section>

            <section id="analysis">
                <h2>5. Coverage Analysis ğŸ“Š</h2>
                
                <h3>Running Analysis</h3>
                <div class="code-block">
# Analyze test coverage
npm run continue

# AI will analyze each API endpoint
# Console output shows detailed coverage analysis
                </div>

                <h3>What the AI Analyzes</h3>
                <ol>
                    <li><strong>Loads Baseline:</strong> Reads your expected scenarios</li>
                    <li><strong>Discovers Tests:</strong> Finds all unit tests in codebase</li>
                    <li><strong>Matches Intelligently:</strong> AI understands which tests cover which scenarios</li>
                    <li><strong>Identifies Gaps:</strong> Points out missing or incomplete coverage</li>
                    <li><strong>Provides Recommendations:</strong> Suggests specific tests to add</li>
                </ol>

                <h3>Sample Analysis Output</h3>
                <div class="code-block">
ğŸ“Š Analyzing: customer-service
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ Baseline: 18 scenarios
âœ“ Unit tests: 45 found

ğŸ¤– AI analyzing coverage...

POST /api/customers:

Scenario 1: "Create customer with valid data returns 201"
  âœ… COVERED by: CustomerControllerTest.testCreateCustomer_Success
  Coverage: COMPLETE
  - Tests valid payload
  - Verifies 201 status code
  - Checks response contains customer ID

Scenario 2: "Customer ID is generated and returned"
  âœ… COVERED by: CustomerControllerTest.testCreateCustomer_Success
  Coverage: COMPLETE
  - Response includes generated UUID
  - ID format is validated

Scenario 3: "Invalid email format returns 400"
  âš ï¸ PARTIALLY COVERED
  Found: CustomerControllerTest.testCreateCustomer_InvalidEmail
  Coverage: PARTIAL - Test checks 400 status but doesn't verify error message
  Missing: Validate error response includes message "Invalid email format"
  Action: Add assertion for error message content

Scenario 4: "Duplicate email returns 409"
  âŒ NOT COVERED
  No test found for duplicate email scenario
  Action: Add test like:
    - Setup: Create customer with email@test.com
    - Action: Attempt to create another customer with same email
    - Assert: Returns 409 status code
    - Assert: Error message indicates duplicate email

GET /api/customers:

Scenario 5: "Get all customers returns 200 with array"
  âœ… COVERED by: CustomerControllerTest.testGetAllCustomers
  Coverage: COMPLETE
                </div>

                <h3>Coverage Status Indicators</h3>
                <table>
                    <tr>
                        <th>Status</th>
                        <th>Symbol</th>
                        <th>Meaning</th>
                        <th>Action</th>
                    </tr>
                    <tr>
                        <td><span class="badge badge-success">COVERED</span></td>
                        <td>âœ…</td>
                        <td>Scenario fully tested</td>
                        <td>No action needed</td>
                    </tr>
                    <tr>
                        <td><span class="badge badge-warning">PARTIAL</span></td>
                        <td>âš ï¸</td>
                        <td>Test exists but incomplete</td>
                        <td>Enhance existing test</td>
                    </tr>
                    <tr>
                        <td><span class="badge badge-info">NOT COVERED</span></td>
                        <td>âŒ</td>
                        <td>No test found</td>
                        <td>Create new test</td>
                    </tr>
                </table>
            </section>

            <section id="interpretation">
                <h2>6. Interpreting Results ğŸ“–</h2>
                
                <h3>Understanding AI Feedback</h3>
                
                <h4>When AI Says "COVERED" âœ…</h4>
                <div class="success-box">
                    <strong>This means:</strong>
                    <ul>
                        <li>AI found a test that covers the scenario</li>
                        <li>Test validates the expected behavior</li>
                        <li>Coverage is complete and comprehensive</li>
                    </ul>
                    <strong>Action:</strong> None required - scenario is properly tested
                </div>

                <h4>When AI Says "PARTIALLY COVERED" âš ï¸</h4>
                <div class="warning-box">
                    <strong>This means:</strong>
                    <ul>
                        <li>A test exists but doesn't fully validate the scenario</li>
                        <li>Some aspects are missing (e.g., error message check)</li>
                        <li>Test is incomplete</li>
                    </ul>
                    <strong>Action:</strong> Create ticket for developer to enhance the test
                </div>

                <h4>When AI Says "NOT COVERED" âŒ</h4>
                <div class="info-box">
                    <strong>This means:</strong>
                    <ul>
                        <li>No test found for this scenario</li>
                        <li>This is a coverage gap</li>
                        <li>Risk: Behavior is not verified</li>
                    </ul>
                    <strong>Action:</strong> Create ticket for developer to add new test
                </div>

                <h3>Creating Actionable Tickets</h3>
                <p>When creating JIRA tickets for gaps:</p>
                <div class="code-block">
Title: Add unit test for [scenario description]

Description:
Coverage analysis shows missing test for:
- API: POST /api/customers
- Scenario: "Duplicate email returns 409"
- Current: No test exists
- Required: Add test to verify duplicate email handling

Acceptance Criteria:
- Create test that attempts duplicate email
- Verify 409 status code is returned
- Verify error message indicates duplicate

Test Name Suggestion:
CustomerControllerTest.testCreateCustomer_DuplicateEmail_Returns409
                </div>
            </section>

            <section id="best-practices">
                <h2>7. Best Practices ğŸ’¡</h2>
                
                <h3>Baseline Management</h3>
                <ul>
                    <li><strong>Version Control:</strong> Always commit baseline files to git</li>
                    <li><strong>Keep Updated:</strong> Update baseline when APIs change</li>
                    <li><strong>Be Specific:</strong> Write clear, testable scenario descriptions</li>
                    <li><strong>Include Status Codes:</strong> Mention expected HTTP responses</li>
                    <li><strong>One Scenario = One Concept:</strong> Don't combine multiple tests</li>
                </ul>

                <h3>Analysis Frequency</h3>
                <table>
                    <tr>
                        <th>Frequency</th>
                        <th>When</th>
                        <th>Purpose</th>
                    </tr>
                    <tr>
                        <td><strong>Weekly</strong></td>
                        <td>During sprint</td>
                        <td>Track progress, identify gaps early</td>
                    </tr>
                    <tr>
                        <td><strong>Sprint End</strong></td>
                        <td>Before demo</td>
                        <td>Verify all stories are tested</td>
                    </tr>
                    <tr>
                        <td><strong>Pre-Release</strong></td>
                        <td>Before deployment</td>
                        <td>Final coverage verification</td>
                    </tr>
                    <tr>
                        <td><strong>Ad-hoc</strong></td>
                        <td>After major changes</td>
                        <td>Validate new functionality</td>
                    </tr>
                </table>

                <h3>Team Collaboration</h3>
                <ul>
                    <li><strong>Share Results:</strong> Post coverage summary in sprint reviews</li>
                    <li><strong>Create Tickets:</strong> Make gaps visible in backlog</li>
                    <li><strong>Track Trends:</strong> Monitor coverage % over time</li>
                    <li><strong>Celebrate Wins:</strong> Recognize improved coverage</li>
                </ul>

                <h3>Quality Metrics</h3>
                <div class="code-block">
Target Metrics:
- Coverage Rate: 90%+ scenarios covered
- Partial Coverage: <5% scenarios
- Analysis Frequency: At least 2x per sprint
- Gap Resolution Time: Within 1 sprint
                </div>
            </section>

            <section id="examples">
                <h2>8. Real Examples ğŸ“š</h2>
                
                <h3>Example 1: REST API Baseline</h3>
                <div class="code-block">
service: order-service

POST /api/orders:
  happy_case:
    - "Create order with valid items returns 201"
    - "Order total is calculated correctly"
    - "Order ID is generated and returned"
  edge_case:
    - "Create order with minimum allowed items (1)"
    - "Create order with maximum allowed items (100)"
    - "Create order with zero-price items"
  error_case:
    - "Create order with empty items array returns 400"
    - "Create order with invalid item ID returns 400"
    - "Create order exceeding credit limit returns 402"
  security:
    - "Create order without authentication returns 401"
    - "Create order for other user returns 403"

GET /api/orders/{id}:
  happy_case:
    - "Get existing order returns 200 with full details"
    - "Order includes all items and totals"
  edge_case:
    - "Get order with 100 items returns within 500ms"
  error_case:
    - "Get non-existent order returns 404"
    - "Get order with invalid UUID format returns 400"
  security:
    - "Get order without auth returns 401"
    - "Get other user's order returns 403"
                </div>

                <h3>Example 2: Microservice Baseline</h3>
                <div class="code-block">
service: payment-service

POST /api/payments/process:
  happy_case:
    - "Process payment with valid card returns 200"
    - "Payment ID and receipt are returned"
    - "Payment status is COMPLETED"
  edge_case:
    - "Process payment with minimum amount (0.01)"
    - "Process payment with maximum amount (9999.99)"
  error_case:
    - "Process payment with declined card returns 402"
    - "Process payment with expired card returns 400"
    - "Process payment with insufficient funds returns 402"
  security:
    - "Process payment encrypts card data"
    - "Process payment logs no sensitive data"
    - "Process payment rate-limited to 10/min"
                </div>
            </section>

            <section id="troubleshooting">
                <h2>9. Troubleshooting ğŸ”</h2>
                
                <h3>Issue: "Claude API key required"</h3>
                <div class="code-block">
Solution: Set environment variable
export CLAUDE_API_KEY="sk-ant-your-key-here"

# Verify it's set
echo $CLAUDE_API_KEY
                </div>

                <h3>Issue: "Baseline file not found"</h3>
                <div class="code-block">
Solution: Create baseline file
mkdir -p .traceability/test-cases/baseline
touch .traceability/test-cases/baseline/your-service-baseline.yml

# Edit file and add scenarios
                </div>

                <h3>Issue: Analysis shows wrong coverage</h3>
                <div class="warning-box">
                    <strong>Possible Causes:</strong>
                    <ul>
                        <li>Scenario description too vague</li>
                        <li>Test name doesn't match scenario intent</li>
                        <li>AI needs more context</li>
                    </ul>
                    <strong>Solution:</strong> Make scenario more specific, include expected status codes
                </div>

                <h3>Issue: Too many "NOT COVERED" results</h3>
                <div class="info-box">
                    <strong>This is normal if:</strong>
                    <ul>
                        <li>You're starting fresh with new baseline</li>
                        <li>Tests haven't been written yet</li>
                        <li>It's early in development</li>
                    </ul>
                    <strong>Action:</strong> Create tickets and track in sprint planning
                </div>

                <h3>Getting Help</h3>
                <div class="success-box">
                    <strong>ğŸ“§ Support Resources:</strong>
                    <ul style="margin-top: 10px;">
                        <li>Developer Guide: <code>docs/DEV_GUIDE.html</code></li>
                        <li>Example Baselines: <code>.traceability/test-cases/baseline/</code></li>
                        <li>Team Contact: QA Automation Team</li>
                    </ul>
                </div>
            </section>

            <footer style="margin-top: 60px; padding-top: 30px; border-top: 2px solid #e2e8f0; text-align: center; color: #718096;">
                <p>AI Test Coverage Analyzer v5.0.0 | QA Guide</p>
                <p>Powered by Claude 3.5 Sonnet | Updated: December 10, 2025</p>
                <p>âœ¨ NEW: Bidirectional Completeness Detection & Change Impact Analysis</p>
            </footer>
        </main>
    </div>
