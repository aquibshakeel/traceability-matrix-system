# ğŸ“Š Reports Guide

**Version:** 6.3.0  
**Last Updated:** December 20, 2025  
**Difficulty:** Intermediate  
**Prerequisites:** [Getting Started Guide](GETTING_STARTED.md)

---

## ğŸ“– Overview

This guide explains how to read, interpret, and act upon the reports generated by the AI-Driven Test Coverage System. You'll learn:
- Understanding each report section
- Interpreting coverage metrics
- Reading AI suggestions
- Acting on gaps and orphans
- Exporting and sharing reports

---

## ğŸ¯ Report Types

The system generates multiple report formats:

| Format | Purpose | Use Case |
|--------|---------|----------|
| **HTML** | Interactive dashboard | Human review, presentations |
| **JSON** | Machine-readable data | CI/CD pipelines, automation |
| **CSV** | Spreadsheet format | Excel analysis, tracking |
| **Markdown** | Documentation format | Version control, wikis |

### Accessing Reports

```bash
# Run analysis (generates all formats)
npm run continue

# Reports location
.traceability/reports/
â”œâ”€â”€ service-name-report.html    # Main interactive dashboard
â”œâ”€â”€ service-name-report.json    # For CI/CD
â”œâ”€â”€ service-name-report.csv     # For spreadsheets
â””â”€â”€ service-name-report.md      # For documentation
```

---

## ğŸŒŸ HTML Report (Premium Dashboard)

The HTML report is the primary interface. It opens automatically after analysis.

### Report Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Executive Summary                   â”‚ â† High-level metrics
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Visual Analytics                    â”‚ â† Charts & graphs
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Business Journeys (E2E)            â”‚ â† User workflow coverage
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Coverage Gaps                       â”‚ â† Missing scenarios
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  API Coverage Analysis              â”‚ â† Per-endpoint details
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Traceability Matrix                â”‚ â† Scenario-to-test mapping
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Orphan APIs                         â”‚ â† Untracked endpoints
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Orphan Tests                        â”‚ â† Tests without scenarios
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ˆ Section 1: Executive Summary

### What It Shows

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  60% Coverage                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â–‘â–‘â–‘â–‘               â”‚
â”‚                               â”‚
â”‚  15 âœ… Fully Covered          â”‚
â”‚   3 âš ï¸ Partially Covered      â”‚
â”‚   7 âŒ Not Covered            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Metrics

**Coverage Percentage**
- Formula: (Fully Covered + Partial Ã— 0.5) / Total Scenarios
- Example: (15 + 3Ã—0.5) / 25 = 66%
- **Good:** >80% (Green)
- **Warning:** 60-80% (Yellow)
- **Critical:** <60% (Red)

**Status Breakdown**
- **Fully Covered (âœ…):** Scenario has complete unit test
- **Partially Covered (âš ï¸):** Test exists but incomplete
- **Not Covered (âŒ):** No test exists

### Understanding the Cards

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 30                  â”‚  â”‚ 6                   â”‚
â”‚ BASELINE SCENARIOS  â”‚  â”‚ TOTAL APIs          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 27                  â”‚  â”‚ 10                  â”‚
â”‚ UNIT TESTS          â”‚  â”‚ ORPHAN TESTS        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**What Each Card Means:**
- **Baseline Scenarios:** Total test cases defined by QA
- **Total APIs:** Number of API endpoints analyzed
- **Unit Tests:** Total unit tests found in codebase
- **Orphan Tests:** Tests without baseline scenarios

---

## ğŸ“Š Section 2: Visual Analytics

### Chart 1: Coverage Distribution (Pie Chart)

```
        Fully Covered (50%)
       â•±                   â•²
      â”‚   Partially (12%)   â”‚
       â•²                   â•±
         Not Covered (38%)
```

**Reading This Chart:**
- **Green:** Scenarios with complete tests
- **Yellow:** Scenarios with partial tests
- **Red:** Scenarios without tests

**Action Items:**
- Focus on reducing red (Not Covered)
- Convert yellow (Partial) to green (Fully Covered)

### Chart 2: Scenarios Without Unit Test (Bar Chart)

```
P0 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (5 scenarios)
P1 â–ˆâ–ˆâ–ˆâ–ˆ (3 scenarios)
P2 â–ˆâ–ˆ (2 scenarios)
P3 â–ˆ (1 scenario)
```

**Priority Definitions:**
- **P0 (Critical):** Security, data integrity, core business
- **P1 (High):** Important error handling, key features
- **P2 (Medium):** Edge cases, secondary features
- **P3 (Low):** Nice-to-have scenarios

**Action Items:**
- Address P0 gaps immediately
- Plan for P1 gaps in current sprint
- Schedule P2/P3 for future sprints

### Chart 3: Orphan Test Priority Breakdown

```
P0 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (8 tests)    Business tests
P1 â–ˆâ–ˆâ–ˆâ–ˆ (2 tests)         Need scenarios
P2 â–ˆâ–ˆ (1 test)           from QA
```

**What This Means:**
- Tests exist but no baseline scenario
- QA needs to add scenarios for these tests
- Higher priority = more critical to document

### Chart 4: Coverage Trend Over Time

```
80% â”¤     â•­â”€â”€â”€â”€â”€
    â”‚   â•­â”€â•¯
60% â”¤ â•­â”€â•¯
    â”‚â•­â•¯
40% â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    0  7  14  21  28 days
```

**Reading This Chart:**
- **Upward trend:** Coverage improving âœ…
- **Flat line:** Coverage stagnant âš ï¸
- **Downward trend:** Coverage declining âŒ

**Causes of Trends:**
- Up: Adding tests, completing gaps
- Down: Adding new features without tests
- Flat: No changes to tests or scenarios

---

## ğŸš€ Section 3: Business Journeys (E2E)

### What Are Business Journeys?

End-to-end user workflows across multiple API calls.

**Example:**
```
User Registration Flow
  Step 1: POST /identity/register     [50% covered]
  Step 2: POST /identity/verify-otp   [0% covered]
  Step 3: POST /identity/activate     [100% covered]

Overall Journey: PARTIALLY_COVERED (âš ï¸)
```

### Journey Statuses

**FULLY_COVERED (ğŸŸ¢)**
- All steps have unit tests
- E2E test exists for the journey
- **Action:** Maintain current coverage

**PARTIALLY_COVERED (ğŸŸ¡)**
- Some steps have unit tests
- OR has unit tests but missing E2E test
- **Action:** Complete missing pieces

**AT_RISK (ğŸŸ )**
- Has E2E test but missing unit tests
- OR has unit tests but missing E2E test
- **Action:** Add missing layer

**NOT_COVERED (ğŸ”´)**
- No unit tests or E2E tests
- **Action:** Immediate attention required

### Weak Points

```
âš ï¸ Weak Points in Journey:
  - Step 2: POST /identity/verify-otp (0/3 scenarios)
  - Missing E2E test for complete flow
```

**What to Do:**
1. Create unit tests for weak steps
2. Implement E2E test for the journey
3. Re-run analysis to verify

---

## âš ï¸ Section 4: Coverage Gaps

### Understanding Gaps

Gaps are scenarios without adequate unit tests.

```
âš ï¸ P0 (Critical) - 5 gaps
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ POST /api/customers                              â”‚
â”‚ When multiple failed attempts, implement         â”‚
â”‚ rate limiting                                    â”‚
â”‚                                                  â”‚
â”‚ ğŸ“‹ Recommendation:                               â”‚
â”‚ Create unit test to cover this scenario         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Priority-Based Action Plan

**P0 Gaps (Do Now)**
```bash
# Example P0 gaps
- Security: SQL injection handling
- Security: XSS protection
- Critical: Account lockout mechanism
- Data Integrity: Transaction rollback

Action: Create tests THIS WEEK
```

**P1 Gaps (Do Soon)**
```bash
# Example P1 gaps
- Error: Invalid email format
- Error: Duplicate account
- Feature: OTP expiration

Action: Plan for CURRENT SPRINT
```

**P2 Gaps (Do Later)**
```bash
# Example P2 gaps
- Edge: Maximum length validation
- Edge: Special characters in name
- Feature: Optional field handling

Action: Schedule for NEXT SPRINT
```

**P3 Gaps (Nice to Have)**
```bash
# Example P3 gaps
- Enhancement: Logging format
- Enhancement: Response optimization
- Documentation: API versioning

Action: Add to BACKLOG
```

### Creating Tests for Gaps

**Step 1: Review the Gap**
```
Scenario: When account is locked, return 403 Forbidden
API: POST /identity/login
Priority: P0
Status: NOT_COVERED
```

**Step 2: Create Unit Test**
```java
@Test
@DisplayName("When account is locked, return 403 Forbidden")
public void testLogin_WithLockedAccount_Returns403() {
    // Arrange
    String userId = "locked-user";
    when(accountService.isLocked(userId)).thenReturn(true);
    
    // Act & Assert
    assertThrows(AccountLockedException.class, () -> {
        authController.login(userId, "password");
    });
}
```

**Step 3: Re-run Analysis**
```bash
npm run continue
# Gap should now be marked as FULLY_COVERED
```

---

## ğŸ¯ Section 5: API Coverage Analysis

### Per-Endpoint View

```
POST /api/customers
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Actual Coverage                      â”‚
â”‚ âœ… 8 Fully covered                  â”‚
â”‚ âš ï¸ 2 Partially covered               â”‚
â”‚ âŒ 2 Missing unit tests              â”‚
â”‚                                      â”‚
â”‚ Coverage: 75% (9/12 scenarios)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scenario List

```
âœ… When customer is created with valid data, return 201
   Test: testCreateCustomer_WithValidData_Returns201
   File: CustomerControllerTest.java:45
   Match: HIGH confidence

âš ï¸ When customer name is at maximum length, accept successfully
   Test: testCreateCustomer_WithLongName_Accepts
   File: CustomerControllerTest.java:67
   Match: MEDIUM confidence
   Issue: Test doesn't verify all edge cases

âŒ When customer is created without authentication, return 401
   No test found
   Priority: P0
   Action: Create security test
```

### Match Confidence Levels

**HIGH (ğŸŸ¢)**
- Test directly maps to scenario
- File location and line number provided
- All assertions present

**MEDIUM (ğŸŸ¡)**
- Test partially covers scenario
- Some assertions missing
- May need enhancement

**LOW (ğŸ”´)**
- Weak match
- Test may be unrelated
- Manual verification needed

### AI Suggestions

```
ğŸ¤– AI-Powered Analysis

ğŸ“Š Coverage Assessment:
Only 67% covered. Action needed for 4 scenarios.

ğŸ†• AI-Suggested Additional Scenarios:

ğŸ” Security (P0):
- When request contains SQL injection in name field
- When attempting CSRF attack, reject with 403
- When using expired JWT token, return 401

âš ï¸ Error Handling (P1):
- When database connection fails, return 500
- When service timeout occurs, handle gracefully

ğŸ“Š Edge Cases (P2):
- When creating customer with maximum allowed fields
- When request body exceeds size limit
```

**Understanding AI Suggestions:**
- **NOT in baseline:** These are additional scenarios
- **Generated from API spec:** Based on endpoint analysis
- **Priority assigned:** P0/P1 only shown
- **Optional:** Consider adding to baseline

---

## ğŸ”— Section 6: Traceability Matrix

### What Is Traceability?

Exact mapping between QA scenarios and unit tests.

```
ğŸ“ Scenario (from baseline):
"When customer is created with valid data, return 201"

âœ… Matched Unit Test:
Test Name: testCreateCustomer_WithValidData_Returns201
File: CustomerControllerTest.java
Line: 45
Confidence: HIGH

Evidence:
- Test name matches scenario description
- HTTP 201 status verified
- Customer ID returned
- All assertions present
```

### Why Traceability Matters

**For QA:**
- Proves scenarios are tested
- Tracks coverage progress
- Identifies testing gaps

**For Developers:**
- Shows which tests map to requirements
- Guides test creation
- Maintains test-requirement alignment

**For Audits:**
- Demonstrates compliance
- Provides evidence of testing
- Enables traceability reports

### Verifying Traceability

**Step 1: Check Match Confidence**
```
HIGH = Reliable, no action needed
MEDIUM = Review test, may need enhancement
LOW = Manual verification required
```

**Step 2: Review Test File**
```bash
# Open the test file
code CustomerControllerTest.java +45
```

**Step 3: Verify Assertions**
```java
// Check test has proper assertions
assertEquals(HttpStatus.CREATED, response.getStatusCode());
assertNotNull(response.getBody().getId());
// etc.
```

---

## âš ï¸ Section 7: Orphan APIs

### What Are Orphan APIs?

APIs with ZERO scenarios AND ZERO tests.

```
âš ï¸ Orphan APIs Detected

PUT /v1/customers/{id}
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Status: COMPLETELY UNTRACKED          â”‚
â”‚                                       â”‚
â”‚ â€¢ No baseline scenarios defined       â”‚
â”‚ â€¢ No unit tests exist                 â”‚
â”‚ â€¢ Endpoint exists in code             â”‚
â”‚                                       â”‚
â”‚ ğŸš¨ HIGH RISK                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“‹ Action Required:
1. QA: Add scenarios to baseline
2. Dev: Create unit tests
3. Both: Ensure coverage
```

### Why Orphan APIs Are Critical

**Risks:**
- Untested functionality in production
- No requirements documentation
- Unclear expected behavior
- Potential security vulnerabilities

**Impact:**
- Production bugs
- Failed audits
- Technical debt
- User issues

### Resolving Orphan APIs

**For QA Team:**
```yaml
# Add to baseline YAML
PUT /v1/customers/{id}:
  happy_case:
    - When customer is updated with valid data, return 200
  error_case:
    - When customer ID doesn't exist, return 404
  security:
    - When updating without authentication, return 401
```

**For Dev Team:**
```java
@Test
public void testUpdateCustomer_WithValidData_Returns200() {
    // Create test
}
```

---

## ğŸ” Section 8: Orphan Tests

### What Are Orphan Tests?

Unit tests that exist but aren't linked to any baseline scenario.

```
ğŸ” 11 Orphan Tests Found

ğŸ’¼ 8 Business Tests (Action Required)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RegisterWithValidCredentialsReturns201â”‚
â”‚ Service: identity-service             â”‚
â”‚ File: IdentityControllerTest.java:45 â”‚
â”‚ Priority: P0                          â”‚
â”‚                                       â”‚
â”‚ ğŸ“‹ Action:                            â”‚
â”‚ QA must add corresponding scenario    â”‚
â”‚ to baseline YAML                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”§ 3 Technical Tests (No Action)
Infrastructure tests, no scenarios needed
```

### Orphan Categories

**Business Tests (ğŸ’¼)**
- Controller tests
- Service tests  
- API integration tests
- **Action:** QA adds scenarios

**Technical Tests (ğŸ”§)**
- Entity tests
- DTO/Mapper tests
- Validation tests
- Utility tests
- **Action:** None (expected)

### Copy-Ready YAML

The report provides ready-to-use YAML:

```yaml
# ğŸ“‹ Copy this to your baseline file

service: identity-service

POST /v1/register:
  happy_case:
    - When register with valid credentials, return 201
    - When register with all optional fields, store complete profile
  
  error_case:
    - When register with existing email, return 409
    - When register with weak password, return 400
```

**How to Use:**
1. Copy the YAML from report
2. Review and adjust as needed
3. Paste into `.traceability/test-cases/baseline/service-baseline.yml`
4. Re-run analysis

---

## ğŸ“„ JSON Report Format

### Structure

```json
{
  "service": "customer-service",
  "timestamp": "2025-12-20T07:00:00Z",
  "summary": {
    "coveragePercent": 66.7,
    "totalScenarios": 30,
    "fullyCovered": 15,
    "partiallyCovered": 5,
    "notCovered": 10,
    "p0Gaps": 3,
    "p1Gaps": 2,
    "p2Gaps": 3,
    "p3Gaps": 2
  },
  "apis": [...],
  "scenarios": [...],
  "tests": [...],
  "gaps": [...],
  "orphanTests": [...]
}
```

### CI/CD Integration

```bash
# Extract coverage percentage
COVERAGE=$(jq '.summary.coveragePercent' report.json)

# Check P0 gaps
P0_GAPS=$(jq '.summary.p0Gaps' report.json)

# Fail if coverage below threshold
if (( $(echo "$COVERAGE < 80" | bc -l) )); then
  echo "âŒ Coverage below 80%: $COVERAGE%"
  exit 1
fi

# Fail if P0 gaps exist
if [ "$P0_GAPS" -gt 0 ]; then
  echo "âŒ $P0_GAPS P0 gaps detected"
  exit 1
fi
```

---

## ğŸ“Š CSV Report Format

### Structure

```csv
API,Scenario,Status,Priority,Test File,Line,Confidence
POST /api/customers,"When created with valid data",FULLY_COVERED,P3,CustomerControllerTest.java,45,HIGH
POST /api/customers,"When SQL injection attempted",NOT_COVERED,P0,,,
```

### Excel Analysis

1. **Open in Excel/Sheets**
2. **Create Pivot Tables:**
   - Rows: Priority
   - Values: Count of Status
   - Filter: Status = NOT_COVERED

3. **Generate Charts:**
   - Coverage by Priority
   - Gaps over time
   - Test distribution

---

## ğŸ“ Markdown Report Format

### Use Cases

- **Version Control:** Commit with code
- **Wiki Documentation:** Paste into Confluence
- **Pull Requests:** Include in PR description
- **Email Reports:** Send to stakeholders

### Example

```markdown
# Coverage Report: customer-service

**Date:** 2025-12-20  
**Coverage:** 66.7% (20/30 scenarios)

## Summary
- âœ… 15 Fully Covered
- âš ï¸ 5 Partially Covered  
- âŒ 10 Not Covered

## P0 Gaps (3)
1. When SQL injection attempted, sanitize input
2. When account locked, return 403
3. When rate limit exceeded, return 429
```

---

## ğŸ¯ Taking Action

### Daily Workflow

**Morning:**
```bash
# Run analysis
npm run continue

# Review report
open .traceability/reports/service-report.html

# Note P0 gaps
```

**During Development:**
```bash
# After adding tests
npm run continue

# Verify gaps closed
# Check coverage improved
```

**Before Commit:**
```bash
# Final check
npm run continue

# Ensure no P0 gaps
# Commit with confidence
```

### Sprint Planning

1. **Export CSV:**
   ```bash
   open .traceability/reports/service-report.csv
   ```

2. **Filter P0/P1 Gaps**

3. **Add to Sprint Backlog:**
   - P0: This sprint
   - P1: Next sprint
   - P2/P3: Future sprints

4. **Track Progress:**
   - Daily coverage checks
   - Update sprint board
   - Report in stand-ups

---

## ğŸ“š Related Documentation

- **ğŸ“– [Getting Started](GETTING_STARTED.md)** - First-time setup
- **âš™ï¸ [Configuration Guide](CONFIGURATION.md)** - All config options
- **ğŸ‘¥ [QA Guide](QA_GUIDE.md)** - For QA team
- **ğŸ‘¨â€ğŸ’» [Developer Guide](DEV_GUIDE.md)** - For developers
- **â“ [Troubleshooting](TROUBLESHOOTING.md)** - Common issues

---

**Version:** 6.3.0 | **Status:** Production Ready âœ…
